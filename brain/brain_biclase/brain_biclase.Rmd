# 1. Introducción

## 1.1. Datos bajados de GDC

## 1.2. Algoritmos escogidos

# 2. Preparación de los datos

En esta sección, tras preparar los datos, se tomarán distintos valores de LFC (Log Fold Change) y COV para determinar el número óptimo de genes diferencialmente expresados (DE), manteniendo un rango aproximado entre 50 y 300 genes. Se presentará una tabla comparativa con el número de genes obtenidos en función de diferentes combinaciones de estos parámetros.

```{r, results='hide', warning=FALSE, message=F, include=FALSE, echo=F}
library(BiocManager)
library(BiocManager)
library(org.Hs.eg.db)
#Incluir KnowSeq y las funciones proporcionadas 
require(KnowSeq)
#source("convert_to_counts.R")
source("geneOntologyEnrichment_updated.R")
source("knowseqReport_updated.R")
require("e1071")
require(CORElearn)
require("caret")
require("praznik")
library(caret)
```

## 2.1. Cargamos los datos completos

```{r}
load(file='samples')
```

En el dataframe samples, anotamos a cuál de los dos tumores principales corresponde cada muestra:

```{r}
load(file='samples_astrocytoma')
samples$Sample.Type[samples$File.ID %in% samples_astrocytoma$File.ID] <- 'astrocytoma'
```

```{r}
load(file='samples_oligodendroglioma')
samples$Sample.Type[samples$File.ID %in% samples_oligodendroglioma$File.ID] <- 'oligodendroglioma'
```

Eliminamos de samples aquellas muestras que sean de glioma mixto:

```{r}
load(file='samples_mixed')
samples <- subset(samples, !(samples$File.ID %in% samples_mixed$File.ID))
```


```{r}
Run <- samples$File.Name
Path <- rep("brain/counts",nrow(samples))
Class <- samples$Sample.Type
```

- Se imprimen el número de muetras por clase, donde se pueden ver que estan bien balanceadas, y se guardan en un fichero csv: 

```{r}
table(Class)
```

```{r, eval=F}
data.info <- data.frame(Run = Run, Path = Path, Class = Class)
write.csv(file = "data_info.csv", x = data.info)
```

- Se cargan y se aunan los ficheros counts:

```{r, eval=F}
countsInfo <- countsToMatrix("data_info.csv", extension = "")
#Guardar fichero de counts por agilizar futuras ejecuciones
save(countsInfo, file='CountsInfo')
```

```{r}
load(file = 'countsInfo')
```

- Exportamos tanto la matriz de datos como los labels a nuevas variables:

```{r}
countsMatrix <- countsInfo$countsMatrix
labels <- countsInfo$labels
```

- Consultamos los Gene Symbols y el GC content de cada gen y los valores de expresion usando la matriz de count y la anotación previamente adquirida:

```{r}
myAnnotation <- getGenesAnnotation(rownames(countsMatrix))
```

```{r, eval=F}
geneExprMatrix <- calculateGeneExpressionValues(countsMatrix, annotation = myAnnotation)
# Eliminamos filas sin anotacion de gen
geneExprMatrix <- geneExprMatrix[!is.na(rownames(geneExprMatrix)),]
# Guardar fichero de Expresión de Gen por agilizar futuras ejecuciones
save(geneExprMatrix, file='geneExprMatrix')
```

```{r}
load(file = 'geneExprMatrix')
```

- Realizamos el analisis de calidad y se seleccionan las muestras que pasen por el filtro (no outliers):

```{r, eval=F}
QAResults <- RNAseqQA(geneExprMatrix, toRemoval = TRUE, 
                      toPNG=FALSE, toPDF=FALSE)
save('QAResults_biclass', file = 'QAResults_biclass')
```

```{r}
# Se cargan para su uso:
load('QAResults')
# Seleccionar muestras que pasen el filtro (no outliers)
qualityMatrix <- QAResults$matrix
qualityLabels <- labels[-which(colnames(geneExprMatrix) %in% QAResults$outliers)]
```

- Creamos el modelo SVA de variables surrogadas para tratar el efecto batch

```{r, eval=F}
# Creamos el modelo SVA de variables surrogadas para tratar el efecto batch
batchMatrix <- batchEffectRemoval(qualityMatrix, qualityLabels, method = "sva")

MATRIZ <- batchMatrix
LABELS <- qualityLabels
# Guardar datos de matriz de Expresión Final y Labels por agilizar futuras ejecuciones
save(MATRIZ, file = 'MATRIZ')
save(LABELS, file = 'LABELS')
```

```{r}
load(file = 'MATRIZ')
load(file = 'LABELS')

#rownames(MATRIZ)<- make.names(rownames(MATRIZ))
```

```{r}
table(LABELS)
```


```{r}
MATRIZ_M <- MATRIZ[, LABELS=="mixed_glioma"]
MATRIZ <- MATRIZ[, !(LABELS=="mixed_glioma")]
```

```{r}
print(dim(MATRIZ))
print(dim(MATRIZ_M))
```
```{r}
LABELS_M <- LABELS[LABELS=="mixed_glioma"]
LABELS <- LABELS[!(LABELS=="mixed_glioma")]
```

```{r}
print(length(LABELS))
print(length(LABELS_M))
```

Así, en el siguiente gráfico se muestran un boxplot ordenado que representa cómo los datos (en este caso, los valores en batchMatrix) se distribuyen para cada grupo definido por las etiquetas qualityLabels. Esto es útil para ver si las muestras se agrupan bien por condición biológica y si el efecto batch se ha corregido adecuadamente:

```{r}
#png('b.png', width = 800, height = 700)
dataPlot(MATRIZ, LABELS, mode = "orderedBoxplot")
```

# 2.1. Tabla con número de genes para distintas combinaciones de LFC y COV.

- Primero, se hace una subdivisión inicial Trn-Test y preparar CV para pruebas definitivas y escoger huella final:

```{r, results='hide'}
require(CORElearn)
set.seed(19)
nfolds<- 5
folds<-cvGenStratified(LABELS, nfolds)

nData<-dim(MATRIZ)[1]
indexTest<-which(folds ==1) # para ejecuciones no CV
indexTrn<-which(folds != 1) # para ejecuciones no CV
XTrn<-MATRIZ[, indexTrn]
XTest<-MATRIZ[,indexTest]
YTrn<-LABELS[indexTrn]
YTest<-LABELS[indexTest]
```


- Del TRAIN se propone extraer genes diferencialmente expresados (DE): vamos a jugar con diferentes valores de COV y LFC:

```{r, eval=F, results='hide'}
# Definir los valores de LFC y COV a probar
LFC_values <- c(0.25, 0.4, 0.5, 0.6, 0.75, 1, 1.5, 2) 
COV_values <- c(1, 2)
p_values <- c(0.001, 0.0005, 0.0001)


# Crear una lista vacía para almacenar los resultados
results <- data.frame(LFC = numeric(0), COV = numeric(0), pvalue=numeric(0), NumGenes = numeric(0))

# Función para extraer los genes diferencialmente expresados con LFC y COV específicos
for (LFC in LFC_values) {
  for (COV in COV_values) {
    for(p in p_values) {
      tryCatch({
        # Ejecutar la función DEGsExtraction para esta combinación de LFC y COV
        DEGsInfo <- DEGsExtraction(XTrn, YTrn, lfc = LFC, cov = COV, pvalue=p)
        
        # Contar el número de genes DEGs (filas de DEGs_Matrix)
        num_genes <- nrow(DEGsInfo$DEG_Results$DEGs_Matrix)
        
        # Agregar los resultados a la tabla
        results <- rbind(results, data.frame(LFC = LFC, COV = COV, pvalue=p, NumGenes = num_genes))
      }, error = function(e) {
        # Si ocurre un error (por ejemplo, si no hay genes DEGs), asignar 0 genes
        results <- rbind(results, data.frame(LFC = LFC, COV = COV, pvalue=p, NumGenes = 0))
        
        # Mostrar un mensaje informativo sobre el error
        message(paste("Error con lfc =", LFC, "y cov =", COV, ": ", e$message))
      })
    }
  }
}

results
save(results, file='results')
```

```{r}
load('results')
results
```

- Como lo conveniente es que salga un número de genes entre 50-300 aproximadamente, filtramos los resultados obtenido anteriormente:

```{r}
resultado_filtrados <- results[results$NumGenes >= 50 & results$NumGenes <= 300, ]
resultado_filtrados
```

- Boxplot y Heatmap de expresion de los 6 DEGs con número de genes entre 50-300:
Observando lo anterior elegimos, por ejemplo, lfc = 0.15 y cov = 1 para obtener la DEGsMatrix.

```{r}
DEGsInfo <- DEGsExtraction(XTrn, YTrn, lfc = 0.4, cov = 1, pvalue=0.001)
DEGsMatrix <- DEGsInfo$DEG_Results$DEGs_Matrix
#png('2b.png', width = 800, height = 600)
dataPlot(DEGsMatrix[1:6,], YTrn, mode = "genesBoxplot")
#png('3b.png', width = 800, height = 600)
dataPlot(DEGsMatrix[1:6,], YTrn, mode = "heatmap")
```

Las clases se diferencian correctamente a simple vista, es decir, no coinciden las medias o las medianas, por ejemplo.

# 3. Selección de características y clasificación con KnowSeq

A continuación, se analizarán y compararán los resultados de los tres algoritmos de selección de características y los tres clasificadores disponibles en la herramienta KnowSeq y el seleccionado para este trabajo: k-Nearest Neighbors (k-NN), Random Forest, Support Vector Machines (SVM) y Regresión Logística multiclase. Para cada clasificador, se evaluará el rendimiento con los cuatro algoritmos de selección (mRMR, RF, DA y Markov Blanket), generando gráficos y tablas de confusión que muestran el desempeño de estas combinaciones.

Para ello, se preparan, en primer lugar, tanto la matriz como los labels:

```{r}
MLMatrix <- t(DEGsMatrix)
MLLabels <- YTrn
```


Los cuatro rankings para la selección de características son:

```{r, results='hide', eval=FALSE}
FSRankingDA <- featureSelection(MLMatrix, MLLabels, mode = "da", vars_selected = colnames(MLMatrix), disease='BrainCancer')
save(FSRankingDA, file='FSRankingDA')
```

```{r, results='hide'}
FSRankingMRMR <- featureSelection(MLMatrix, MLLabels, mode = "mrmr", vars_selected = colnames(MLMatrix))
FSRankingRF <- featureSelection(MLMatrix, MLLabels, mode = "rf", vars_selected = colnames(MLMatrix))
load('FSRankingDA')
```

Implementación del algoritmo de selección de características Markov Blanket:

```{r, eval=F}
library(infotheo)  # Para calcular información mutua

# Función para calcular la información mutua entre dos variables
calculate_mutual_info <- function(X, Y) {
  # Discretizar las variables y calcular la información mutua
  return(mutinformation(discretize(X), discretize(Y)))
}

# Algoritmo hacia atrás Markov Blanket
featureSelection_MB <- function(data, target) {
   # Asegurarse de que 'data' sea una matriz y 'target' sea un vector
  if (!is.matrix(data)) {
    stop("La variable 'data' debe ser una matriz.")
  }
  if (!is.vector(target)) {
    stop("La variable 'target' debe ser un vector.")
  }
  
  # Inicializar el conjunto de características (columnas de la matriz)
  XG <- colnames(data)  # Conjunto de todas las características
  
  # Asegurar que el vector 'target' tenga la misma longitud que las filas de 'data'
  if (length(target) != nrow(data)) {
    stop("El tamaño de 'target' no coincide con el número de filas de 'data'.")
  }

  # Lista para almacenar las pérdidas de las características
  feature_loss <- numeric(length(XG))  # Para almacenar las pérdidas por eliminar cada característica
  
  # Iterar hasta que el conjunto de características sea pequeño
  while (length(XG) > 0) {
    # Inicializar el vector de pérdidas
    loss_values <- numeric(length(XG))  
    
    # Calcular las pérdidas para cada característica
    for (i in 1:length(XG)) {
      Xj <- XG[i]
      
      # Obtener el marco de Markov Mj (las características más informativas respecto a Xj)
      Mj <- setdiff(XG, Xj)  # Inicializamos Mj sin Xj (esto es un proxy de MB)
      
      # Verificar si hay suficientes columnas en Mj para realizar el cálculo de información mutua
      if (length(Mj) == 0) {
        next
      }
      
      # Calcular la información mutua I({Mj ∪ Xj}, Y)
      IMjXj_Y <- tryCatch({
        calculate_mutual_info(data[, c(Mj, Xj)], target)
      }, error = function(e) {
        NA  # Si ocurre un error, devolver NA
      })
      
      # Calcular la información mutua I(Mj, Y)
      IMj_Y <- tryCatch({
        calculate_mutual_info(data[, Mj], target)
      }, error = function(e) {
        NA  # Si ocurre un error, devolver NA
      })
      
      # Si alguna de las informaciones mutuas no es válida (NA), no calcular la pérdida
      if (is.na(IMjXj_Y) | is.na(IMj_Y)) {
        loss_values[i] <- NA
      } else {
        # Calcular la pérdida para Xj
        loss_values[i] <- IMjXj_Y - IMj_Y
      }
    }
    
    # Si todas las pérdidas son NA, detener el proceso
    if (all(is.na(loss_values))) {
      cat("Todas las pérdidas son NA. Deteniendo el algoritmo.\n")
      break
    }
    
    # Filtrar las pérdidas no-NA y seleccionar la característica con la menor pérdida
    valid_loss_values <- loss_values[is.finite(loss_values)]
    
    # Si no hay valores válidos para calcular la pérdida, detener
    if (length(valid_loss_values) == 0) {
      cat("No hay valores válidos para calcular las pérdidas. Deteniendo el algoritmo.\n")
      break
    }
    
    # Seleccionar la característica con la menor pérdida
    best_feature_to_remove <- XG[which.min(valid_loss_values)]
    
    # Almacenar la pérdida y la característica eliminada
    feature_loss[which(XG == best_feature_to_remove)] <- loss_values[which(XG == best_feature_to_remove)]
    
    # Eliminar la característica seleccionada del conjunto
    XG <- setdiff(XG, best_feature_to_remove)
    
    cat("Eliminada característica:", best_feature_to_remove, "\n")
  }
  
  # Crear un data frame con el nombre de la característica y su pérdida
  feature_ranking <- data.frame(
    Feature = colnames(data),
    Loss = feature_loss
  )
  
  # Ordenar el ranking de características por la pérdida (menor a mayor)
  feature_ranking <- feature_ranking[order(feature_ranking$Loss), ]
  
  # Devolver el ranking de las características ordenado
  
  return(feature_ranking)
}
```

```{r, eval=F}
#Feature selection con Markov Blanket:
FSRanking_MB <- featureSelection_MB(MLMatrix, MLLabels)$Feature
save(FSRanking_MB, file='FSRanking_MB')
```

```{r}
load('FSRanking_MB')
```

## 3.1. Clasificador k-NN

Calculados los rankings de carcaterísticas, comencemos con el clasificador k-NN.

### 3.1.1. Selección de características con FSRankingMRMR:

Esta sección se centra en la evaluación del rendimiento del modelo de clasificación basado en los k-Vecinos más cercanos (KNN) utilizando una selección de características mediante el método mRMR (Minimum Redundancy Maximum Relevance). Primero, se entrena el modelo, `knn_trn_mrmr`, utilizando la función `knn_trn` con un subconjunto de 10 biomarcadores seleccionados, `FSRankingMRMR[1:10]`, evaluando su desempeño en términos de puntuación F1 y precisión. Luego, se prueba el modelo `knn_test_mrmr` con la función `knn_test`, con datos de la partición test para comparar los resultados de entrenamiento y prueba. Finalmente, se visualizan las métricas mediante gráficos comparativos para analizar la efectividad del modelo.

```{r,  results='hide'}
# Evaluar biomarcadores en TRN
knn_trn_mrmr<- knn_trn(MLMatrix, MLLabels, vars_selected = names(FSRankingMRMR[1:10])) 
knn_results_mrmr <- rbind(knn_trn_mrmr$F1Info$meanF1[1:10],knn_trn_mrmr$accuracyInfo$meanAccuracy)
```

```{r, echo=F}
#dataPlot(knn_results_mrmr, MLLabels, legend = c("F1","Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r, results='hide'}
# Evaluar huella genética en TEST. Es multiclase, mejor ver accuracy y F1-Score
knn_test_mrmr<-knn_test(MLMatrix, MLLabels, t(XTest), YTest, vars_selected = names(FSRankingMRMR[1:10]), bestK=knn_trn_mrmr$bestK)
knn_results_mrmr_test <- rbind(knn_trn_mrmr$F1Info$meanF1[1:10], knn_test_mrmr$f1Vector, knn_trn_mrmr$accuracyInfo$meanAccuracy, knn_test_mrmr$accVector)
```

```{r, echo=F}
#dataPlot(knn_results_mrmr_test, MLLabels, legend = c("Trn F1-score","Test F1-score", "Trn Accuracy","Test Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r, echo=F}
#png('f1.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- knn_results_mrmr_test[1,num_genes]
Test_F1 <- knn_results_mrmr_test[2,num_genes]
Trn_Acc <- knn_results_mrmr_test[3,num_genes]
Test_Acc <- knn_results_mrmr_test[4,num_genes]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l")
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("bottomright",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```

Cuando num_genes = 5, se estabiliza las curvas alcanzando el 60% de acierto (accuracy) y de F1 para la evaluación del conjunto train y test. Comprobamos esta información con la matriz de confusión para el conjunto test:

```{r,echo=F}
#png('m1.png', width = 500, height = 400)
dataPlot(knn_test_mrmr$cfMats[[2]]$table, MLLabels, mode = "confusionMatrix")
#dev.off()

#Podríamos elegir 3, pero la mejora es mínima
```

### 3.1.2. Selección de características con FSRankingRF:

Utilicemos ahora las 10 primeras características seleccionadas con Random Forest para entrenar el modelo 

```{r, results='hide'}
# Evaluar biomarcadores en TRN. Es multiclase, mejor ver accuracy y F1-Score
knn_trn_rf <- knn_trn(MLMatrix, MLLabels, vars_selected = FSRankingRF[1:10])
knn_results_rf <- rbind(knn_trn_rf$F1Info$meanF1[1:10],knn_trn_rf$accuracyInfo$meanAccuracy)
```

```{r, echo=F}
#dataPlot(knn_results_rf, MLLabels, legend = c("F1","Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r, results='hide'}
# Evaluar huella genética en TEST. Es multiclase, mejor ver accuracy y F1-Score
knn_test_rf <- knn_test(MLMatrix, MLLabels, t(XTest), YTest, vars_selected= FSRankingRF[1:10], bestK=knn_trn_rf$bestK)
knn_results_rf_test <- rbind(knn_trn_rf$F1Info$meanF1[1:10], knn_test_rf$f1Vector, knn_trn_rf$accuracyInfo$meanAccuracy, knn_test_rf$accVector)
```

```{r, echo=F}
#dataPlot(knn_results_rf_test, MLLabels, legend = c("Trn F1-score","Test F1-score", "Trn Accuracy","Test Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r, echo=F}
#png('f2.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- knn_results_rf_test[1,num_genes]
Test_F1 <- knn_results_rf_test[2,num_genes]
Trn_Acc <- knn_results_rf_test[3,num_genes]
Test_Acc <- knn_results_rf_test[4,num_genes]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l")
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("bottomright",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```


Mientras que el accuracy se mantiene muy constante para el conjunto train, cuando num_genes está entre 3 y 6, el accuracy comienza a superar el 60%. Comprobemos esta información con la matriz de confusión para el conjunto test. En primer lugar, para una huella de tres genes:

```{r}
#png('m2.png', width = 500, height = 400)
dataPlot(knn_test_rf$cfMats[[2]]$table, MLLabels, mode = "confusionMatrix")
```
En segundo lugar, para una huella de seis genes:

El umento del porcentaje de acierto es muy poco tras elegir el docle de genes. Por tanto, la huella escogida en este caso podría ser 3.

### 3.1.3. Selección de variables con FSRankingDA:


```{r, results='hide'}
# Evaluar biomarcadores en TRN. Es multiclase, mejor ver accuracy y F1-Score
knn_trn_da <- knn_trn(MLMatrix, MLLabels, vars_selected = names(FSRankingDA[1:20]))
knn_results_da <- rbind(knn_trn_da$F1Info$meanF1[1:20],knn_trn_da$accuracyInfo$meanAccuracy)
```

```{r, echo=F}
#dataPlot(knn_results_da, MLLabels, legend = c("F1","Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r, results='hide'}
# Evaluar huella genética en TEST. Es multiclase, mejor ver accuracy y F1-Score
knn_test_da <- knn_test(MLMatrix, MLLabels, t(XTest), YTest, vars_selected= names(FSRankingDA[1:20]), bestK=knn_trn_da$bestK)
knn_results_da_test <- rbind(knn_trn_da$F1Info$meanF1[1:20], knn_test_da$f1Vector, knn_trn_da$accuracyInfo$meanAccuracy, knn_test_da$accVector)
```

```{r, echo=F}
#dataPlot(knn_results_da_test, MLLabels, legend = c("Trn F1-score","Test F1-score", "Trn Accuracy","Test Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r,echo=FALSE}
#png('f3.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- knn_results_da_test[1,num_genes]
Test_F1 <- knn_results_da_test[2,num_genes]
Trn_Acc <- knn_results_da_test[3,num_genes]
Test_Acc <- knn_results_da_test[4,num_genes]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l")
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("bottomright",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```

Parece que a partir de 10 genes, dejan de haber picos muy pronunciados para el train. Sin embargo, a partir de ese valor el F1 y el accuracy del conjunto test están entorno al 50%, luego, no lograremos una bune clasificación a menos que escojamos un número muy elevado de genes. Se contrasta esta información con la matriz de confusión para el conjunto test: 

```{r, echo=F}
#png('m3.png', width = 500, height = 400)
dataPlot(knn_test_da$cfMats[[2]]$table, MLLabels, mode = "confusionMatrix")
```

### 3.1.4. Selección de variables con FSRanking_MB:
Por último, se entrena el modelo `knn_trn_mb` con el ranking creado con el método Markov Blanket y se ajusta el modelo test `knn_test_mb` con el mejor k obtenido en el entrenamiento:

```{r, results='hide'}
knn_trn_mb <- knn_trn(MLMatrix, MLLabels, vars_selected = FSRanking_MB[1:20])
knn_results_mb <- rbind(knn_trn_mb$F1Info$meanF1[1:20],knn_trn_mb$accuracyInfo$meanAccuracy)
knn_test_mb <- knn_test(MLMatrix, MLLabels, t(XTest), YTest, vars_selected=FSRanking_MB[1:20], bestK=knn_trn_mb$bestK)
knn_results_mb_test <- rbind(knn_trn_mb$F1Info$meanF1[1:20], knn_test_mb$f1Vector, knn_trn_mb$accuracyInfo$meanAccuracy, knn_test_mb$accVector)
```

```{r,echo=FALSE}
#png('f4.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- knn_results_mb_test[1,num_genes]
Test_F1 <- knn_results_mb_test[2,num_genes]
Trn_Acc <- knn_results_mb_test[3,num_genes]
Test_Acc <- knn_results_mb_test[4,num_genes]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l")
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("bottomright",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```
Parece que sería apropiado escoger 10 genes o 14 aunque es a partir de 18 genes cuando se empieza a obtener un accuracy más alto, tanto para el train como para el test. Veamos las matrices de confusión para 10 genes, ya que una huella de 14 o 18 ya sería demasiado:


```{r, echo=F}
#png('m4.2.png', width = 500, height = 400)
dataPlot(knn_test_mb$cfMats[[4]]$table, MLLabels, mode = "confusionMatrix")
```

No se obtiene una buena clasificación para la cantidad de genes elegidos. Por tanto, la combinación clasificador-seleccionador para el ejemplo del cáncer de cerebro no es apropiada.


### 3.1.5. Conclusiones 

Para el clasificador k-NN, el algoritmo de selección de selección de características mRMR es el que mejor porcetajes de Accuracy propociona: 63.46% con cinco genes seleccionados. En condiciones similares, para Random Forest, el accuracy y el F1 están entorno al 60-62% para una huella de entre 3 y 6 genes. Sin embargo, para el DA y el MB, no se llega al 55% de acierto, ni si siquiera con una huella de 10 genes. En conlusión y por simplicidad, para obtener mejores resultados con el clasificador k-NN, se podría escoger el método de selección de características mRMR y una huella de cinco genes.

## 3.2. Clasificador RandomForest

En esta sección se repetirá el procedimiento aplicado con el algoritmo k-NN (k-Vecinos más cercanos) utilizando los cuatro rankings de características disponibles. Se evaluará el rendimiento del modelo en términos de métricas de clasificación como precision y F1-score , tanto en los datos de entrenamiento como de prueba. Posteriormente, se compararán los resultados obtenidos para cada ranking con el fin de determinar qué características permiten una mejor clasificación de los tres tipos de cáncer de cerebro analizados.

### 3.2.1. Selección de variables con FSRankingMRMR

Definamos los modelos de entrenamiento y test, `rf_trn_mrmr` y `rf_test_mrmr`, respectivamente, haciendo uso de las funciones `rf_trn` y `rf_test`.

```{r,  results='hide', eval=F}
# Evaluar biomarcadores en TRN. Es multiclase, mejor ver accuracy y F1-Score
rf_trn_mrmr<- rf_trn(MLMatrix, MLLabels, vars_selected = names(FSRankingMRMR[1:10]),numFold = 5)
save(rf_trn_mrmr, file='rf_trn_mrmr')
```
```{r}
load('rf_trn_mrmr')
rf_results_mrmr <- rbind(rf_trn_mrmr$F1Info$meanF1[1:10],rf_trn_mrmr$accuracyInfo$meanAccuracy)
#dataPlot(rf_results_mrmr, MLLabels, legend = c("F1","Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r,  results='hide', eval=F}
# Evaluar huella genética en TEST. Es multiclase, mejor ver accuracy y F1-Score
rf_test_mrmr <- rf_test(MLMatrix, MLLabels, t(XTest), YTest, vars_selected= names(FSRankingMRMR[1:10]),bestParameters=rf_trn_mrmr$bestParameters)

save(rf_test_mrmr, file='rf_test_mrmr')
```

```{r}
load('rf_test_mrmr')
rf_results_mrmr_test <- rbind(rf_trn_mrmr$F1Info$meanF1[1:10], rf_test_mrmr$f1Vector, rf_trn_mrmr$accuracyInfo$meanAccuracy, rf_test_mrmr$accVector)
#dataPlot(rf_results_mrmr_test, MLLabels, legend = c("Trn F1-score","Test F1-score", "Trn Accuracy","Test Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r,echo=FALSE}
#png('f5.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- rf_results_mrmr_test[1,1:10]
Test_F1 <- rf_results_mrmr_test[2,1:10]
Trn_Acc <- rf_results_mrmr_test[3,1:10]
Test_Acc <- rf_results_mrmr_test[4,1:10]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l")
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("bottomright",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```

De la gráfica anterior destaca la armonía entre el accuracy y el F1 para el conjunto test y train. En este caso, se comienzan a obtener mejores valores de accuracy y F1 para train con una huella de 4 genes, aunque después haya un descenso del porcentaje de acierto paulatino para el conjunto test. Para comprobar numéricamente las metricas se presenta la matriz de confusión para el conjunto test:

```{r, echo=F}
#png('m5.png', width=500, height = 400)
dataPlot(rf_test_mrmr$cfMats[[2]]$table, MLLabels, mode = "confusionMatrix")
```

Este es el modelo con mayor porcentaje de acierto y menor huella hasta el momento.

### 3.2.2. Selección de variables con FSRankingRF

Se definen de la misma manera los modelos `rf_trn_rf` y `rf_test_rf`, haciendo uno del Ranking creado a partir de Random Forest.

```{r,  results='hide', eval=F}
# Evaluar biomarcadores en TRN. Es multiclase, mejor ver accuracy y F1-Score
rf_trn_rf<- rf_trn(MLMatrix, MLLabels, vars_selected = (FSRankingRF[1:10]),numFold = 5)
save(rf_trn_rf, file='rf_trn_rf')
```

```{r}
load('rf_trn_rf')
rf_results_rf <- rbind(rf_trn_rf$F1Info$meanF1[1:10],rf_trn_rf$accuracyInfo$meanAccuracy)
#dataPlot(rf_results_rf, MLLabels, legend = c("F1","Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r,  results='hide', eval=F}
# Evaluar huella genética en TEST. Es multiclase, mejor ver accuracy y F1-Score
rf_test_rf <- rf_test(MLMatrix, MLLabels, t(XTest), YTest, vars_selected = (FSRankingRF[1:10]), bestParameters=rf_trn_rf$bestParameters)
save(rf_test_rf, file='rf_test_rf')
```

```{r}
load('rf_test_rf')
rf_results_rf_test <- rbind(rf_trn_rf$F1Info$meanF1[1:10], rf_test_rf$f1Vector, rf_trn_rf$accuracyInfo$meanAccuracy, rf_test_rf$accVector)
#dataPlot(rf_results_rf_test, MLLabels, legend = c("Trn F1-score","Test F1-score", "Trn Accuracy","Test Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r,echo=FALSE}
#png('f6.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- rf_results_rf_test[1,1:10]
Test_F1 <- rf_results_rf_test[2,1:10]
Trn_Acc <- rf_results_rf_test[3,1:10]
Test_Acc <- rf_results_rf_test[4,1:10]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l")
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("bottomright",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```

Como en el caso anterior, la mejor huella es cuando num_genes = 2. A continuación, se muestra la matriz de confusión para el conjunto test, con el objetivo de porder hacer conclusiones más fiables:

```{r, echo=F}
#png('m6.png', width=500, height = 400)
dataPlot(rf_test_rf$cfMats[[3]]$table, MLLabels, mode = "confusionMatrix")
```

Destaca que el accuracy en este caso y en el anterior para una huella de 2 genes, es el mismo. Por tanto, para distinguirlos podríamos fijarnos en que el F1-score para el ranking del método mRMR (59.1%) es algo mayor que en este caso.

### 3.2.3. Selección de variables con FSRankingDA

De la misma forma, se ajustan los modelos `rf_trn_da` y `rf_test_da` para el ranking de DA. Se llevará a cabo también la evaluación del rendimiento del modelo mediante métricas como la precision y el F1-score , tanto en los datos de entrenamiento como en los de prueba.

```{r,  results='hide', eval=F}
# Evaluar biomarcadores en TRN. Es multiclase, mejor ver accuracy y F1-Score
rf_trn_da<- rf_trn(MLMatrix, MLLabels, vars_selected = names(FSRankingDA[1:10]), numFold = 5) 
save(rf_trn_da, file='rf_trn_da')
```

```{r}
load('rf_trn_da')
rf_results_da <- rbind(rf_trn_da$F1Info$meanF1[1:10],rf_trn_da$accuracyInfo$meanAccuracy)
#dataPlot(rf_results_da, MLLabels, legend = c("F1","Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r, results='hide', eval=F}
# Evaluar huella genética en TEST. Es multiclase, mejor ver accuracy y F1-Score
rf_test_da <- rf_test(MLMatrix, MLLabels, t(XTest), YTest, vars_selected = names(FSRankingDA[1:10]), bestParameters=rf_trn_da$bestParameters)
save(rf_test_da, file='rf_test_da')
```

```{r}
load('rf_test_da')
rf_results_da_test <- rbind(rf_trn_da$F1Info$meanF1[1:10], rf_test_da$f1Vector, rf_trn_da$accuracyInfo$meanAccuracy, rf_test_da$accVector)
#dataPlot(rf_results_da_test, MLLabels, legend = c("Trn F1-score","Test F1-score", "Trn Accuracy","Test Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r,echo=FALSE}
#png('f7.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- rf_results_da_test[1,1:10]
Test_F1 <- rf_results_da_test[2,1:10]
Trn_Acc <- rf_results_da_test[3,1:10]
Test_Acc <- rf_results_da_test[4,1:10]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l")
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("bottomright",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```

Se observa que, en este caso, el F1-score y el accuracy son más bajos. Además, el accuracy y el F1 del train, a partir de num_genes = 4, parece que aumenta pero a penas alcanza el 60%. Veamos lo explicado en la siguiente matriz de confusión para el conjunto test:

```{r, echo=F}
#png('m7.png', width=500, height = 400)
dataPlot(rf_test_da$cfMats[[2]]$table, MLLabels, mode = "confusionMatrix")
```

Con la mejor huella para el conjunto train, el test a penas acierta en el 50% de las ocasiones.

### 3.2.4. Selección de variables con FSRankingMB

Finalmente, busquemos la huella para el Ranking de MB, entrenando los modelos `rf_trn_mb` y `rf_test_mb`.

```{r, eval=F}
rf_trn_mb <- rf_trn(MLMatrix, MLLabels, vars_selected = FSRanking_MB[1:10])
save(rf_trn_mb, file='rf_trn_mb')
```
```{r}
load('rf_trn_mb')
```

```{r}
rf_results_mb <- rbind(rf_trn_mb$F1Info$meanF1[1:10],rf_trn_mb$accuracyInfo$meanAccuracy)
rf_test_mb <- rf_test(MLMatrix, MLLabels, t(XTest), YTest, vars_selected=FSRanking_MB[1:10], bestParameters = rf_trn_mb$bestParameters)
rf_results_mb_test <- rbind(rf_trn_mb$F1Info$meanF1[1:10], rf_test_mb$f1Vector, rf_trn_mb$accuracyInfo$meanAccuracy, rf_test_mb$accVector)
```


```{r,echo=FALSE}
#png('f8.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- rf_results_mb_test[1,1:10]
Test_F1 <- rf_results_mb_test[2,1:10]
Trn_Acc <- rf_results_mb_test[3,1:10]
Test_Acc <- rf_results_mb_test[4,1:10]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l")
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("topright",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```

Destaca el descenso del F1-score para el conjunto train a partir de 3 genes. Elegimos esta huella aún observando que el accuracy del train está entorno al 50%. Veamos lo obtenido para el conjunto test en la siguiente matriz de confusión:

```{r, echo=F}
#png('m8.png', width=500, height = 400)
dataPlot(rf_test_da$cfMats[[4]]$table, MLLabels, mode = "confusionMatrix")
```

### 3.2.5. Conclusiones 

Si nos fijamos en el porcentaje de acierto del clasificador Random Forest, si seleccionamos características con mRMR, el accuracy y el F1 del conjunto test están entorno al 64.4% y 57.4%, respectivamente, con una huella de 4 genes. Para una huella de 2 genes, con RF se obtienen unos porcentajes de acierto y F1 de 65.4% y 58.1%, respectivamente. En este último caso, además el F1 es algo superior para el conjunto test. Por otro lado, si observamos la matriz de confusión del seleccionador de características DA o MB se concluye que los porcentajes de acierto son menores que los anteriores, estando entrono al 50%, y no siendo, por tanto, buenas opciones.

En conclusión, para el clasificador Random Forest se podría elegir RF como seleccionador de características con una huella de 2 genes. 


## 3.3. Clasificador SVM

En esta sección se abordará el entrenamiento de los modelos train y test del clasificador SVM (Support Vector Machine) para la clasificación de los tres tipos de cáncer cerebral. A lo largo de esta sección se utilizaran las funciones `svm_trn` y `svm_test2`. Esta última función es la misma que la función del KnowSeq `svm_test` pero con los arreglos que se indican para el buen funcionamiento en estro problema:

```{r}
svm_test2 <-function(train,labelsTrain,test,labelsTest,vars_selected,bestParameters){

  if(!is.data.frame(train) && !is.matrix(train)){
    
    stop("The train argument must be a dataframe or a matrix.")
    
  }
  
  if(dim(train)[1] != length(labelsTrain)){
    
    stop("The length of the rows of the argument train must be the same than the length of the lablesTrain. Please, ensures that the rows are the samples and the columns are the variables.")
    
  }
  
  if(!is.character(labelsTrain)  && !is.factor(labelsTrain)){stop("The class of the labelsTrain parameter must be character vector or factor.")}
  if(is.character(labelsTrain)){ labelsTrain <- as.factor(labelsTrain) }
  
  if(!is.character(labelsTest)  && !is.factor(labelsTest)){stop("The class of the labelsTest parameter must be character vector or factor.")}
  if(is.character(labelsTest)){ labelsTest <- as.factor(labelsTest) }
  
  if(!is.data.frame(test) && !is.matrix(test)){
    
    stop("The test argument must be a dataframe or a matrix.")
    
  }
  
  if(dim(test)[1] != length(labelsTest)){
    
    stop("The length of the rows of the argument test must be the same than the length of the lablesTest. Please, ensures that the rows are the samples and the columns are the variables.")
    
  }
  
  train <- as.data.frame(apply(train,2,as.double))
  train <- train[,vars_selected]
  test <- as.data.frame(apply(test,2,as.double))
  test <- test[,vars_selected]
  
  train = vapply(train, function(x){ 
    max <- max(x)
    min <- min(x)
    if(max >  min){
      x <- ((x - min) / (max - min)) * 2 - 1
    }
    else{
      x
    }}, double(nrow(train)))
  
  train <- as.data.frame(train)
  
  test = vapply(test, function(x){ 
    max <- max(x)
    min <- min(x)
    if(max >  min){
      x <- ((x - min) / (max - min)) * 2 - 1
    }
    else{
      x
    }}, double(nrow(test)))
  
  test <- as.data.frame(test)

  accVector <- double()
  sensVector <- double()
  specVector <- double()
  f1Vector <- double()
  cfMatList  <- list()
  colNames <- colnames(train)
  for(i in seq_len(dim(test)[2])){
    cat(paste("Testing with ", i," variables...\n",sep=""))
    columns <- make.names(c(colNames[seq(i)])) # make.names()convierte los nombres en identificadores sintácticamente válidos
    tr_ctr <- trainControl(method="none")
    colnames(train)<-make.names(colnames(train)) # se alteran los nombres para que coincidan con los de las columnas
    dataForTrt <- data.frame(cbind(subset(train, select=columns),labelsTrain))
    colnames(train)[seq(i)] <- make.names(columns)
    svm_model <- train(labelsTrain ~ ., data = dataForTrt, type = "C-svc", 
                       method = "svmRadial", preProc = c("center", "scale"),
                       trControl = tr_ctr, 
                       tuneGrid=data.frame(sigma=getElement(bestParameters, "gamma"), 
                                           C = getElement(bestParameters, "C")))
    colnames(test)<-make.names(colnames(test)) # alteramos los nombres en el conjunto test para poder extraer del dataframe test los genes con el mismo nombre que en la variable columns
    testX = subset(test, select=columns)
    unkX <- testX
    colnames(unkX) <- make.names(colnames(testX))
    colnames(testX) <- make.names(colnames(testX))
    predicts <- extractPrediction(list(my_svm=svm_model), testX = testX, unkX = unkX,
                                  unkOnly = !is.null(unkX) & !is.null(testX))
    
    predicts <- predicts$pred
    
    cfMat<-confusionMatrix(predicts,labelsTest)
    
    if (length(levels(labelsTrain))==2){
      sens <- cfMat$byClass[[1]]
      spec <- cfMat$byClass[[2]]
      f1 <- cfMat$byClass[[7]]
    } else{
      sens <- mean(cfMat$byClass[,1])
      spec <- mean(cfMat$byClass[,2])
      cfMat$byClass[,7][is.na(cfMat$byClass[,7])] <- 0 
      # CAMBIO:
      # Es mejor reemplazar los valores NA en esta etapa para permitir que el F1-score se grafique correctamente. 
      # Si el reemplazo se realiza después, el promedio de los tres F1-scores inicialmente resultará en NA y luego        en cero, lo que excluye el F1 de las demás clases. 
      # Reemplazar el NA aquí garantiza que el cálculo de la media considere un F1 de 0 en caso de que la precisión       sea NA y el recall sea 0. Esto sucede cuando una clase no es predicha ni correctamente ni incorrectamente, 
      # es decir, cuando el número de falsos positivos y falsos negativos es 0.
      f1 <- mean(cfMat$byClass[,7])
    }
    
    cfMatList[[i]] <- cfMat
    accVector[i] <- cfMat$overall[[1]]
    sensVector[i] <- sens
    specVector[i] <- spec
    f1Vector[i] <- f1
    
    #if(is.na(f1Vector[i])) f1Vector[i] <- 0 
  }

  cat("Classification done successfully!\n")
  names(accVector) <- vars_selected
  names(sensVector) <- vars_selected
  names(specVector) <- vars_selected
  names(f1Vector) <- vars_selected

  results <- list(cfMatList,accVector,sensVector,specVector,f1Vector)
  names(results) <- c("cfMats","accVector","sensVector","specVector","f1Vector")
  invisible(results)

}
```

Realizamos el mismo cambio relativo al cálculo del valor F1 para el código fuente de la función `svm_train`:

```{r}
svm_trn <- function(data, labels, vars_selected, numFold = 10) {
  if (!is.data.frame(data) && !is.matrix(data)) {
    stop("The data argument must be a dataframe or a matrix.")
  }
  if (dim(data)[1] != length(labels)) {
    stop("The length of the rows of the argument data must be the same than the length of the lables. Please, ensures that the rows are the samples and the columns are the variables.")
  }
  
  if (!is.character(labels) && !is.factor(labels)) {
    stop("The class of the labels parameter must be character vector or factor.")
  }
  if (is.character(labels)) {
    labels <- as.factor(labels)
  }
  
  if (numFold %% 1 != 0 || numFold == 0) {
    stop("The numFold argument must be integer and greater than 0.")
  }
  
  data <- as.data.frame(apply(data, 2, as.double))
  data <- data[, vars_selected]
  
  data <- vapply(data, function(x) {
    max <- max(x)
    min <- min(x)
    if(max >  min){
      x <- ((x - min) / (max - min)) * 2 - 1
    }
    else{
      x
    }
  }, double(nrow(data)))
  
  data <- as.data.frame(data)
  
  fitControl <- trainControl(method = "cv", number = 10)
  cat("Tuning the optimal C and G...\n")
  
  grid_radial <- expand.grid(
    sigma = c(
      0, 0.01, 0.02, 0.025, 0.03, 0.04,
      0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.25, 0.5, 0.75, 0.9
    ),
    C = c(
      0.01, 0.05, 0.1, 0.25, 0.5, 0.75,
      1, 1.5, 2, 5
    )
  )
  
  dataForTunning <- cbind(data, labels)
  colnames(dataForTunning) <- make.names(colnames(dataForTunning))
  Rsvm_sb <- train(labels ~ ., data = dataForTunning, type = "C-svc", method = "svmRadial", preProc = c("center", "scale"), trControl = fitControl, tuneGrid = grid_radial)
  
  bestParameters <- c(C = Rsvm_sb$bestTune$C, gamma = Rsvm_sb$bestTune$sigma)
  cat(paste("Optimal cost:", bestParameters[1], "\n"))
  cat(paste("Optimal gamma:", bestParameters[2], "\n"))
  
  acc_cv <- matrix(0L, nrow = numFold, ncol = dim(data)[2])
  sens_cv <- matrix(0L, nrow = numFold, ncol = dim(data)[2])
  spec_cv <- matrix(0L, nrow = numFold, ncol = dim(data)[2])
  f1_cv <- matrix(0L, nrow = numFold, ncol = dim(data)[2])
  cfMatList <- list()
  # compute size of val fold
  lengthValFold <- dim(data)[1]/numFold
  
  # reorder the data matrix in order to have more
  # balanced folds
  positions <- rep(seq_len(dim(data)[1]))
  randomPositions <- sample(positions)
  data <- data[randomPositions,]
  labels <- labels[randomPositions]

  for (i in seq_len(numFold)) {
    cat(paste("Training fold ", i, "...\n", sep = ""))
    
    # obtain validation and training folds
    valFold <- seq(round((i-1)*lengthValFold + 1 ), round(i*lengthValFold))
    trainDataCV <- setdiff(seq_len(dim(data)[1]), valFold)
    testDataset<- data[valFold,]
    trainingDataset <- data[trainDataCV,]
    labelsTrain <- labels[trainDataCV]
    labelsTest <- labels[valFold]
    colNames <- colnames(trainingDataset)
    
    for (j in seq_len(length(vars_selected))) {
      columns <- c(colNames[seq(j)])
      tr_ctr <- trainControl(method="none")
      dataForTrt <- data.frame(cbind(subset(trainingDataset, select=columns),labelsTrain))
      colnames(dataForTrt)[seq(j)] <- make.names(columns)
      svm_model <- train(labelsTrain ~ ., data = dataForTrt, type = "C-svc", 
                         method = "svmRadial", preProc = c("center", "scale"),
                         trControl = tr_ctr, 
                         tuneGrid=data.frame(sigma = bestParameters[2], C = bestParameters[1]))
      
      testX = subset(testDataset, select=columns)
      unkX <- testX
      colnames(unkX) <- make.names(colnames(testX))
      colnames(testX) <- make.names(colnames(testX))
      predicts <- extractPrediction(list(my_svm=svm_model), testX = testX, unkX = unkX,
                                    unkOnly = !is.null(unkX) & !is.null(testX))
      
      predicts <- predicts$pred
      
      cfMatList[[i]] <- confusionMatrix(predicts, labelsTest)
      acc_cv[i, j] <- cfMatList[[i]]$overall[[1]]
      
      if (length(levels(labelsTrain))==2){
        sens <- cfMatList[[i]]$byClass[[1]]
        spec <- cfMatList[[i]]$byClass[[2]]
        f1 <- cfMatList[[i]]$byClass[[7]]
      } else{
        sens <- mean(cfMatList[[i]]$byClass[,1])
        spec <- mean(cfMatList[[i]]$byClass[,2])
        cfMatList[[i]]$byClass[,7][is.na(cfMatList[[i]]$byClass[,7])] <- 0 # CAMBIO
        f1 <- mean(cfMatList[[i]]$byClass[,7])
      }
      
      sens_cv[i, j] <- sens
      spec_cv[i, j] <- spec
      f1_cv[i, j] <- f1
      
      if(is.na(sens_cv[i,j])) sens_cv[i,j] <- 0
      if(is.na(spec_cv[i,j])) spec_cv[i,j] <- 0
      if(is.na(f1_cv[i,j])) f1_cv[i,j] <- 0
    }
  }
  
  meanAcc <- colMeans(acc_cv)
  names(meanAcc) <- colnames(acc_cv)
  sdAcc <- apply(acc_cv, 2, sd)
  accuracyInfo <- list(meanAcc, sdAcc)
  names(accuracyInfo) <- c("meanAccuracy","standardDeviation")
  
  
  meanSens <- colMeans(sens_cv)
  names(meanSens) <- colnames(sens_cv)
  sdSens <- apply(sens_cv, 2, sd)
  sensitivityInfo <- list(meanSens, sdSens)
  names(sensitivityInfo) <- c("meanSensitivity","standardDeviation")
  
  
  meanSpec <- colMeans(spec_cv)
  names(meanSpec) <- colnames(spec_cv)
  sdSpec <- apply(spec_cv, 2, sd)
  specificityInfo <- list(meanSpec, sdSpec)
  names(specificityInfo) <- c("meanSpecificity","standardDeviation")
  
  
  meanF1 <- colMeans(f1_cv)
  names(meanF1) <- colnames(f1_cv)
  sdF1 <- apply(f1_cv, 2, sd)
  F1Info <- list(meanF1, sdF1)
  names(F1Info) <- c("meanF1","standardDeviation")
  
  cat("Classification done successfully!\n")
  results_cv <- list(cfMatList,accuracyInfo,sensitivityInfo,specificityInfo,F1Info,bestParameters)
  names(results_cv) <- c("cfMats","accuracyInfo","sensitivityInfo","specificityInfo","F1Info","bestParameters")
  invisible(results_cv)
  
}
```

### 3.3.1. Selección de variables con FSRankingMRMR

Comenzamos con las variables seleccionadas con mRMR, entrenando los modelos `svm_trn_mrmr` y `svm_test_mrmr`.

```{r, results='hide', eval=F}
# Evaluar biomarcadores en TRN. Es multiclase, mejor ver accuracy y F1-Score
svm_trn_mrmr<- svm_trn(MLMatrix, MLLabels, vars_selected = names(FSRankingMRMR[1:10]),numFold = 5)

save(svm_trn_mrmr, file='svm_trn_mrmr')
```

```{r}
load('svm_trn_mrmr')
svm_results_mrmr <- rbind(svm_trn_mrmr$F1Info$meanF1[1:10],svm_trn_mrmr$accuracyInfo$meanAccuracy)
#dataPlot(svm_results_mrmr, MLLabels, legend = c("F1","Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```


```{r,  results='hide'}
svm_test_mrmr <- svm_test2(MLMatrix, MLLabels, t(XTest), YTest, vars_selected=names(FSRankingMRMR[1:10]), bestParameters= svm_trn_mrmr$bestParameters)
svm_results_mrmr_test <- rbind(svm_trn_mrmr$F1Info$meanF1[1:10], svm_test_mrmr$f1Vector, svm_trn_mrmr$accuracyInfo$meanAccuracy, svm_test_mrmr$accVector)
```


```{r, echo=F}
#dataPlot(svm_results_mrmr_test, MLLabels, legend = c("Trn F1-score","Test F1-score", "Trn Accuracy","Test Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r,echo=FALSE}
#png('f9.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- svm_results_mrmr_test[1,1:10]
Test_F1 <- svm_results_mrmr_test[2,1:10]
Trn_Acc <- svm_results_mrmr_test[3,1:10]
Test_Acc <- svm_results_mrmr_test[4,1:10]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l")
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("bottomright",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```

En este caso, para num_genes = 6, destaca el pico de F1 para el conjunt train, por tanto, elegimos esta huella a partir de la cual no hay cambios tan bruscos. Se comprueba con la matriz de confusión para el conjunto test:

```{r, echo=F}
#png('m9.png', width=500, height = 400)
dataPlot(svm_test_mrmr$cfMats[[3]]$table, MLLabels, mode = "confusionMatrix")
```
Cabe destacar que ningún astocitoma u oligodendroglioma se ha predicho como glioma mixto. Sin embargo, al contrario sí y en numerosas ocasiones, 17 y 6, respectivamente.

### 3.3.2. Selección de variables con FSRankingRF:

En este caso, se entrenan los modelos `svm_train_rf` y `svm_test_rf`. Calculando las m-etricas correspondientes para la valoreación de la clasificación en el conjunto test. Los mejores parámetros obtenidos en este caso son C = 0.75 y gamma = 0.03.

```{r,  results='hide', eval=F}
# Evaluar biomarcadores en TRN. Es multiclase, mejor ver accuracy y F1-Score
svm_trn_rf<- svm_trn(MLMatrix, MLLabels, vars_selected = (FSRankingRF[1:10]),numFold = 5)
save(svm_trn_rf, file='svm_trn_rf')
```

```{r}
load('svm_trn_rf')
svm_results_rf <- rbind(svm_trn_rf$F1Info$meanF1[1:10],svm_trn_rf$accuracyInfo$meanAccuracy)
#dataPlot(svm_results_rf, MLLabels, legend = c("F1","Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r, results='hide'}
# Evaluar huella genética en TEST. Es multiclase, mejor ver accuracy y F1-Score
svm_test_rf <- svm_test2(MLMatrix, MLLabels, t(XTest), YTest, vars_selected = (FSRankingRF[1:10]), bestParameters= svm_trn_rf$bestParameters)
svm_results_rf_test <- rbind(svm_trn_rf$F1Info$meanF1[1:10], svm_test_rf$f1Vector, svm_trn_rf$accuracyInfo$meanAccuracy, svm_test_rf$accVector)
```

```{r, echo=F}
#dataPlot(svm_results_rf_test, MLLabels, legend = c("Trn F1-score","Test F1-score", "Trn Accuracy","Test Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```


```{r,echo=FALSE}
#png('f10.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- svm_results_rf_test[1,1:10]
Test_F1 <- svm_results_rf_test[2,1:10]
Trn_Acc <- svm_results_rf_test[3,1:10]
Test_Acc <- svm_results_rf_test[4,1:10]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l")
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("bottomright",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```

En este caso, elegiría una huella de 4 genes ya que, a partir de ahí, el crecimeinto del F1 y accuracy en train es gradual. Sin embargo, si observamos las métricas del conjunto test, en realidad comienzan a ascender a partir de 6 genes. Vemaos así, la matriz de confusión para el conjunto test cuando la huella es 4:

```{r}
#png('m10.png', width=500, height = 400)
dataPlot(svm_test_rf$cfMats[[3]]$table, MLLabels, mode = "confusionMatrix")
```

### 3.3.3. Selección de variables con FSRankingDA:

Repetimos el porceso para el ranking de DA. 

```{r,  results='hide', eval=F}
# Evaluar biomarcadores en TRN. Es multiclase, mejor ver accuracy y F1-Score
svm_trn_da<- svm_trn(MLMatrix, MLLabels, vars_selected = names(FSRankingDA[1:10])) 
save(svm_trn_da, file='svm_trn_da')
```

```{r}
load('svm_trn_da')
svm_results_da <- rbind(svm_trn_da$F1Info$meanF1[1:10],svm_trn_da$accuracyInfo$meanAccuracy)
#dataPlot(svm_results_da, MLLabels, legend = c("F1","Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r, results='hide'}
# Evaluar huella genética en TEST. Es multiclase, mejor ver accuracy y F1-Score
svm_test_da <- svm_test2(MLMatrix, MLLabels, t(XTest), YTest, vars_selected = names(FSRankingDA[1:10]), bestParameters= svm_trn_da$bestParameters)
svm_results_da_test <- rbind(svm_trn_da$F1Info$meanF1[1:10], svm_test_da$f1Vector, svm_trn_da$accuracyInfo$meanAccuracy, svm_test_da$accVector)
```

```{r, echo=F}
#dataPlot(svm_results_da_test, MLLabels, legend = c("Trn F1-score","Test F1-score", "Trn Accuracy","Test Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r,echo=FALSE}
#png('f11.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- svm_results_da_test[1,1:10]
Test_F1 <- svm_results_da_test[2,1:10]
Trn_Acc <- svm_results_da_test[3,1:10]
Test_Acc <- svm_results_da_test[4,1:10]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l", col = )
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("bottomright",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```

A partir de 2 genes, aparece que el accuracy el F1 para el conjunto de entrenamiento mejora y se mantiene bastante constante. Aunque, para las métricas del conjunto test, es a partir de 5 genes cuando mejoran. Veamos la matriz de confusión para el conjunto test y una huella de dos genes:

```{r,echo=F}
#png('m11.png', width=500, height = 400)
dataPlot(svm_test_da$cfMats[[2]]$table, MLLabels, mode = "confusionMatrix")
```
La clase glioma mixto no es predecida por el modelo. Además, tiene un accracy muy bajo, el cuál para una huella de 5 genes mejora al 55%. Este aumento no mejora notablemente la clasificación del modelo.

### 3.3.4. Selección de variables con FSRanking_MB:

Por último, veamos los resultados para el `FSRanking_MB`.

```{r, eval=F}
svm_trn_mb <- svm_trn(MLMatrix, MLLabels, vars_selected = FSRanking_MB[1:10])
save(svm_trn_mb, file='svm_trn_mb')
```
```{r}
load('svm_trn_mb')
```

```{r}
svm_results_mb <- rbind(svm_trn_mb$F1Info$meanF1[1:10],svm_trn_mb$accuracyInfo$meanAccuracy)
svm_test_mb <- svm_test2(MLMatrix, MLLabels, t(XTest), YTest, vars_selected=FSRanking_MB[1:10], bestParameters = svm_trn_mb$bestParameters)
svm_results_mb_test <- rbind(svm_trn_mb$F1Info$meanF1[1:10], svm_test_mb$f1Vector, svm_trn_mb$accuracyInfo$meanAccuracy, svm_test_mb$accVector)
```

```{r,echo=FALSE}
#png('f12.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- svm_results_mb_test[1,1:10]
Test_F1 <- svm_results_mb_test[2,1:10]
Trn_Acc <- svm_results_mb_test[3,1:10]
Test_Acc <- svm_results_mb_test[4,1:10]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l")
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("bottomright",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```
Si nos fijamos en el accuracy y el F1 del train, podríamos escoger una huella de 2 genes. Veamos la matriz de confusión para esta huella en el conjunto test:

```{r, echo=F}
#png('m12.png', width=500, height = 400)
dataPlot(svm_test_mb$cfMats[[4]]$table, MLLabels, mode = "confusionMatrix")
```
Como vemos es una de las peores combinaciones clasificador-seleccionador hasta el momento.

### 3.3.5. Conclusiones 

En el caso del clasificador SVM, si seleccionamos características DA o con MB, se tiene un accuracy muy poco superior al 40% con una huella de 2 genes; con una opción muy baja a mejora si aumentamos esta huella. Sin embargo, para el algoritmo de selección mRMR y una huella de seis genes, el accuracy es del 62.5%, igual al del Random Forest con la misma huella. Además, para Random Forest es con el que también se obtiene mayor porcentaje de F1, 60%. Por ello, nos quedaremos con esta última combinación.

## 3.4. Clasificador Regresión Logística

Se diseña en esta sección la sunción `logistic_train2` ayudandonos del código base de la función de KnowSeq `knn_trn`:

```{r}
data<-MLMatrix
labels<-MLLabels
vars_selected = names(FSRankingMRMR[1:10])
numFold = 5
logistic_trn2 <- function(data, labels, vars_selected, numFold = 10, LOOCV = FALSE){
  
  if (!is.data.frame(data) && !is.matrix(data)) {
    stop("The data argument must be a dataframe or a matrix.")
  }
  if (dim(data)[1] != length(labels)) {
    stop("The length of the rows of the argument data must be the same as the length of the labels. Please ensure that the rows are the samples and the columns are the variables.")
  }
  
  if (!is.character(labels) && !is.factor(labels)) {
    stop("The class of the labels parameter must be a character vector or factor.")
  }
  
  if (is.character(labels)) {
    labels <- as.factor(labels)
  }
  
  if (numFold %% 1 != 0 || numFold == 0) {
    stop("The numFold argument must be an integer and greater than 0.")
  }
  
  data <- as.data.frame(apply(data, 2, as.double))
  data <- data[, vars_selected]
  
  # Scaling the data between -1 and 1
  data = vapply(data, function(x) { 
    max_val <- max(x)
    min_val <- min(x)
    if (max_val > min_val) {
      x <- ((x - min_val) / (max_val - min_val)) * 2 - 1
    }
    return(x)
  }, double(nrow(data)))
  
  data <- as.data.frame(data)
  
  fitControl <- trainControl(method = "repeatedcv", number = numFold, repeats = 3)
  cat("Tuning the optimal model...\n")
  
  # Use logistic regression with multinomial family for 3 classes
  logistic_model <- train(data, labels, method = "glm", trControl = fitControl, preProcess = c("center", "scale"), family = "binomial")
  
  cat(paste("Optimal model tuned.\n"))
  
  if (LOOCV == FALSE) { 
    accuracyInfo <- list()
    sensitivityInfo <- list()
    specificityInfo <- list()
    f1Info <- list()
    
    acc_cv <- matrix(0L, nrow = numFold, ncol = length(vars_selected))
    sens_cv <- matrix(0L, nrow = numFold, ncol = length(vars_selected))
    spec_cv <- matrix(0L, nrow = numFold, ncol = length(vars_selected))
    f1_cv <- matrix(0L, nrow = numFold, ncol = length(vars_selected))
    
    cfMatList <- list()
    lengthValFold <- dim(data)[1] / numFold
    
    positions <- rep(seq_len(dim(data)[1]))
    randomPositions <- sample(positions)
    data <- data[randomPositions, ]
    labels <- labels[randomPositions]
    
    for (i in seq_len(numFold)) {
      cat("Running K-Fold Cross-Validation...\n")
      cat(paste("Training fold ", i, "...\n", sep = ""))
      
      valFold <- seq(round((i - 1) * lengthValFold + 1), round(i * lengthValFold))
      trainDataCV <- setdiff(seq_len(dim(data)[1]), valFold)
      testDataset <- data[valFold, ]
      trainingDataset <- data[trainDataCV, ]
      labelsTrain <- labels[trainDataCV]
      labelsTest <- labels[valFold]
      
      # Train logistic regression model for 3 classes
      logistic_mod <- glm(labelsTrain ~ ., data = trainingDataset, family="binomial")
      predicts <- predict(logistic_mod, testDataset)
      
      cfMatList[[i]] <- confusionMatrix(predicts, labelsTest)
      acc_cv[i, 1] <- cfMatList[[i]]$overall[[1]]
      
      # Compute sensitivity, specificity, and F1 score
      if (length(levels(labelsTrain))==2){
          sens <- cfMatList[[i]]$byClass[[1]]
          spec <- cfMatList[[i]]$byClass[[2]]
          f1 <- cfMatList[[i]]$byClass[[7]]
        } else{
          sens <- mean(cfMatList[[i]]$byClass[,1])
          spec <- mean(cfMatList[[i]]$byClass[,2])
          f1 <- mean(cfMatList[[i]]$byClass[,7])
        }
      sens_cv[i, 1] <- sens
      spec_cv[i, 1] <- spec
      f1_cv[i, 1] <- f1
      
      if (is.na(sens_cv[i, 1])) sens_cv[i, 1] <- 0
      if (is.na(spec_cv[i, 1])) spec_cv[i, 1] <- 0
      #if (is.na(f1_cv[i, 1])) f1_cv[i, 1] <- 0
      
      for (j in 2:length(vars_selected)) {
        logistic_mod <- glm(labelsTrain ~ ., data = trainingDataset[, 1:j], family="binomial")
        predicts <- predict(logistic_mod, testDataset[, 1:j])
        
        cfMatList[[i]] <- confusionMatrix(predicts, labelsTest)
        acc_cv[i, j] <- cfMatList[[i]]$overall[[1]]
        
        cfMatList[[i]]$byClass[, 1][is.na(cfMatList[[i]]$byClass[, 1])] <- 0
        sens <- mean(cfMatList[[i]]$byClass[, 1])
        cfMatList[[i]]$byClass[, 2][is.na(cfMatList[[i]]$byClass[, 2])] <- 0
        spec <- mean(cfMatList[[i]]$byClass[, 2])
        cfMatList[[i]]$byClass[, 7][is.na(cfMatList[[i]]$byClass[, 7])] <- 0
        f1 <- mean(cfMatList[[i]]$byClass[, 7])
        
        sens_cv[i, j] <- sens
        spec_cv[i, j] <- spec
        f1_cv[i, j] <- f1
        
        if (is.na(sens_cv[i, j])) sens_cv[i, j] <- 0
        if (is.na(spec_cv[i, j])) spec_cv[i, j] <- 0
        #if (is.na(f1_cv[i, j])) f1_cv[i, j] <- 0
      }
    }
    
    # Calculate mean and standard deviation
    meanAcc <- colMeans(acc_cv)
    sdAcc <- apply(acc_cv, 2, sd)
    accuracyInfo <- list(meanAcc, sdAcc)
    names(accuracyInfo) <- c("meanAccuracy", "standardDeviation")
    
    meanSens <- colMeans(sens_cv)
    sdSens <- apply(sens_cv, 2, sd)
    sensitivityInfo <- list(meanSens, sdSens)
    names(sensitivityInfo) <- c("meanSensitivity", "standardDeviation")
    
    meanSpec <- colMeans(spec_cv)
    sdSpec <- apply(spec_cv, 2, sd)
    specificityInfo <- list(meanSpec, sdSpec)
    names(specificityInfo) <- c("meanSpecificity", "standardDeviation")
    
    meanF1 <- colMeans(f1_cv)
    sdF1 <- apply(f1_cv, 2, sd)
    F1Info <- list(meanF1, sdF1)
    names(F1Info) <- c("meanF1", "standardDeviation")
    
    cat("Classification done successfully!\n")
    results_cv <- list(cfMatList, accuracyInfo, sensitivityInfo, specificityInfo, F1Info, logistic_model)
    names(results_cv) <- c("cfMats", "accuracyInfo", "sensitivityInfo", "specificityInfo", "F1Info", "logisticModel")
    invisible(results_cv)
  
  } else {
    # LOOCV section (Leave-One-Out Cross-Validation)
    cat("Running Leave-One-Out Cross-Validation...\n")
    accuracyInfo <- numeric()
    sensitivityInfo <- numeric()
    specificityInfo <- numeric()
    F1Info <- numeric()
    predictions <- list()
    cfMatList <- list()
    
    for (i in 1:dim(data)[1]) {
      # Perform LOOCV
      trainDataCV <- setdiff(1:dim(data)[1], i)
      testData <- data[i, , drop = FALSE]
      trainLabels <- labels[trainDataCV]
      testLabel <- labels[i]
      
      logistic_mod <- glm(labelsTrain ~ ., data = data[trainDataCV, , drop = FALSE], family="binomial")
      predictLabel <- predict(logistic_mod, testData)
      
      cfMatList[[i]] <- confusionMatrix(predictLabel, testLabel)
      accuracyInfo[i] <- cfMatList[[i]]$overall[[1]]
      sensitivityInfo[i] <- cfMatList[[i]]$byClass[[1]]
      specificityInfo[i] <- cfMatList[[i]]$byClass[[2]]
      F1Info[i] <- cfMatList[[i]]$byClass[[7]]
    }
    
    results_loocv <- list(cfMatList, accuracyInfo, sensitivityInfo, specificityInfo, F1Info)
    names(results_loocv) <- c("cfMats", "accuracyInfo", "sensitivityInfo", "specificityInfo", "F1Info")
    invisible(results_loocv)
  }
}
```

Se muestra a continuación la implementación de la función `logistic_test_multiclase`. Para crearla nos hemos ayudado de la función `svm_test`:

```{r}
library(nnet)
logistic_test_multiclase <- function(tren, etiquetasTren, prueba, etiquetasPrueba, vars_selected, logistic_trn_mrmr) {
  
  # Validar tipos de datos de los argumentos
  if (!is.data.frame(tren) && !is.matrix(tren)) {
    stop("El argumento tren debe ser un marco de datos o una matriz.")
  }
  
  if (dim(tren)[1] != length(etiquetasTren)) {
    stop("La longitud de las filas del argumento tren debe ser la misma que la longitud de etiquetasTren.")
  }
  
  if (!is.character(etiquetasTren) && !is.factor(etiquetasTren)) {
    stop("La clase del parámetro etiquetasTren debe ser un vector de caracteres o un factor.")
  }
  if (is.character(etiquetasTren)) { etiquetasTren <- as.factor(etiquetasTren) }
  
  if (!is.character(etiquetasPrueba) && !is.factor(etiquetasPrueba)) {
    stop("La clase del parámetro etiquetasPrueba debe ser un vector de caracteres o un factor.")
  }
  if (is.character(etiquetasPrueba)) { etiquetasPrueba <- as.factor(etiquetasPrueba) }
  
  if (!is.data.frame(prueba) && !is.matrix(prueba)) {
    stop("El argumento prueba debe ser un marco de datos o una matriz.")
  }
  
  if (dim(prueba)[1] != length(etiquetasPrueba)) {
    stop("La longitud de las filas del argumento prueba debe ser la misma que la longitud de etiquetasPrueba.")
  }
  
  # Seleccionar las variables necesarias de los datos
  tren <- as.data.frame(apply(tren, 2, as.double))
  tren <- tren[, vars_selected, drop = FALSE]
  
  prueba <- as.data.frame(apply(prueba, 2, as.double))
  prueba <- prueba[, vars_selected, drop = FALSE]
  
  # Normalizar las características entre -1 y 1
  tren <- vapply(tren, function(x) {
    max_val <- max(x)
    min_val <- min(x)
    if (max_val > min_val) {
      x <- ((x - min_val) / (max_val - min_val)) * 2 - 1
    }
    return(x)
  }, double(nrow(tren)))
  tren <- as.data.frame(tren)
  
  prueba <- vapply(prueba, function(x) {
    max_val <- max(x)
    min_val <- min(x)
    if (max_val > min_val) {
      x <- ((x - min_val) / (max_val - min_val)) * 2 - 1
    }
    return(x)
  }, double(nrow(prueba)))
  prueba <- as.data.frame(prueba)
  
  # Inicializar vectores para almacenar los resultados
  accVector <- double()
  sensVector <- double()
  specVector <- double()
  f1Vector <- double()
  cfMatList <- list()
  predicVector <- list()
  
  # Usar el modelo entrenado logistic_trn_mrmr$logisticModel$finalModel
  best_decay <- logistic_trn_mrmr$logisticModel$finalModel$decay
  
  # Realizar predicciones en los datos de prueba usando el modelo entrenado
  logistic_model <- glm(etiquetasTren~., data=subset(tren, select = c(colnames(tren)[1])), decay = best_decay, family="binomial")
  predicciones <- predict(logistic_model, subset(prueba, select = c(colnames(prueba)[1])), type = "class")
  predictScores <- predict(logistic_model,subset(prueba, select = c(colnames(prueba)[1])), type = "prob")
  
  # Calcular la matriz de confusión y las métricas
  cfMat <- confusionMatrix(predicciones, etiquetasPrueba)
  sens <- mean(cfMat$byClass[, "Sensitivity"])
  spec <- mean(cfMat$byClass[, "Specificity"])
  cfMat$byClass[, "F1"][is.na(cfMat$byClass[, "F1"])] <- 0
  f1 <- mean(cfMat$byClass[, "F1"])
  
  # Guardar los resultados para este conjunto de características
  cfMatList[[1]] <- cfMat
  accVector[1] <- cfMat$overall["Accuracy"]
  sensVector[1] <- sens
  specVector[1] <- spec
  f1Vector[1] <- f1
  predicVector[[1]] <- predictScores
  
  # Si hay más variables, repetimos el proceso con más características
  if (dim(prueba)[2] > 1) {
    for (i in 2:dim(prueba)[2]) {
      cat(paste("Probando con", i, "variables...\n", sep = " "))
      
      logistic_model2 <- glm(etiquetasTren~., data=tren[,1:i], decay = best_decay, family="binomial")
      predicciones <- predict(logistic_model2, prueba[, 1:i], type = "class")
      predictScores <- predict(logistic_model2, prueba[, 1:i], type = "prob")
      
      cfMat <- confusionMatrix(predicciones, etiquetasPrueba)
      sens <- mean(cfMat$byClass[, "Sensitivity"])
      spec <- mean(cfMat$byClass[, "Specificity"])
      cfMat$byClass[, "F1"][is.na(cfMat$byClass[, "F1"])] <- 0
      f1 <- mean(cfMat$byClass[, "F1"])
      
      cfMatList[[i]] <- cfMat
      accVector[i] <- cfMat$overall["Accuracy"]
      sensVector[i] <- sens
      specVector[i] <- spec
      f1Vector[i] <- f1
      predicVector[[i]] <- predictScores
    }
  }
  
  cat("¡Clasificación realizada con éxito!\n")
  
  # Asignar nombres a los resultados
  names(accVector) <- vars_selected
  names(sensVector) <- vars_selected
  names(specVector) <- vars_selected
  names(f1Vector) <- vars_selected
  
  # Devolver los resultados como una lista
  resultados <- list(cfMatList, accVector, sensVector, specVector, f1Vector, predicVector)
  names(resultados) <- c("cfMats", "accVector", "sensVector", "specVector", "f1Vector", "predicciones")
  
  invisible(resultados)
}
```

En estas funciones también se ha considerado que, si no es posible calcular el F1 para alguna clase e iteración debido a que no se predice ni correctamente ni erróneamente esa clase, el valor de dicho F1 será cero, lo que permite calcular adecuadamente la media de los tres F1 y tener en cuenta los F1 de las demás clases.

En esta sección, usaremos estas funciones específicas para entrenar y evaluar los modelos de regresión logística en este problema de clasificación multiclase.

### 3.4.1. Selección de variables con FSRankingMRMR

Utilizamos las funciones implementadas para entrenar los modelos `logistic_trn_mrmr` y `logistic_test_mrmr`, y calcular las métricas.

```{r, results='hide'}
# Aplicar la función con regresión logística
logistic_trn_mrmr <- logistic_trn2(MLMatrix, MLLabels, vars_selected = names(FSRankingMRMR[1:10]), numFold = 5)
logistic_results_mrmr <- rbind(logistic_trn_mrmr$F1Info$meanF1[1:10],logistic_trn_mrmr$accuracyInfo$meanAccuracy)
#dataPlot(svm_results_mrmr, MLLabels, legend = c("F1","Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```


```{r,  results='hide'}
# Evaluar huella genética en TEST. Es multiclase, mejor ver accuracy y F1-Score
logistic_test_mrmr <- logistic_test_multiclase(MLMatrix, MLLabels, t(XTest), YTest, names(FSRankingMRMR[1:10]), logistic_trn_mrmr)

#################################################################################3
logistic_results_mrmr_test <- rbind(logistic_trn_mrmr$F1Info$meanF1[1:10], logistic_test_mrmr$f1Vector, logistic_trn_mrmr$accuracyInfo$meanAccuracy, logistic_test_mrmr$accVector)
```


```{r, echo=F}
#dataPlot(logistic_results_mrmr_test, MLLabels, legend = c("Trn F1-score","Test F1-score", "Trn Accuracy","Test Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r,echo=FALSE}
#png('f13.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- logistic_results_mrmr_test[1,1:10]
Test_F1 <- logistic_results_mrmr_test[2,1:10]
Trn_Acc <- logistic_results_mrmr_test[3,1:10]
Test_Acc <- logistic_results_mrmr_test[4,1:10]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l")
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("bottomright",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```

En este caso, para num_genes = 3 las métricas comienzan a mejorar, tanto en train como en test, aunque sin un porcentaje muy alto y siendo similares en train y test. Se comprueba con la matriz de confusión para el conjunto test y una huella de 3 genes:

```{r, echo=F}
#png('m13.png', width=500, height = 400)
dataPlot(logistic_test_mrmr$cfMats[[3]]$table, MLLabels, mode = "confusionMatrix")
```
Esta es la mejor predicción hasta el momento. Es interesante destacar que la clase que más se confunde es el glioma mixto con el oligodendroglioma. Esto puede deberse a que el glioma mixto presenta características del oligodendroglioma, lo que hace más difícil diferenciarlas en el modelo. Dado que ambas clases comparten ciertas similitudes en su perfil genético o características de imagen, la confusión es comprensible, lo que resalta la importancia de seguir perfeccionando los métodos de clasificación para mejorar la precisión.

### 3.4.2. Selección de variables con FSRankingRF

Ajustamos ahora los modelos de test y train para las variables seleccionadas por Random Forest:

```{r,  results='hide'}
# Aplicar la función con regresión logística
logistic_trn_rf <- logistic_trn2(MLMatrix, MLLabels, vars_selected = (FSRankingRF[1:10]), numFold = 5)
logistic_results_rf <- rbind(logistic_trn_rf$F1Info$meanF1[1:10],logistic_trn_rf$accuracyInfo$meanAccuracy)
#dataPlot(svm_results_rf, MLLabels, legend = c("F1","Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```


```{r, results='hide'}
# Evaluar huella genética en TEST. Es multiclase, mejor ver accuracy y F1-Score
logistic_test_rf <- logistic_test_multiclase(MLMatrix, MLLabels, t(XTest), YTest, (FSRankingRF[1:10]), logistic_trn_rf)

#################################################################################3
logistic_results_rf_test <- rbind(logistic_trn_rf$F1Info$meanF1[1:10], logistic_test_rf$f1Vector, logistic_trn_rf$accuracyInfo$meanAccuracy, logistic_test_rf$accVector)
```

```{r, echo=F}
#dataPlot(svm_results_rf_test, MLLabels, legend = c("Trn F1-score","Test F1-score", "Trn Accuracy","Test Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```


```{r,echo=FALSE}
#png('f14.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- logistic_results_rf_test[1,1:10]
Test_F1 <- logistic_results_rf_test[2,1:10]
Trn_Acc <- logistic_results_rf_test[3,1:10]
Test_Acc <- logistic_results_rf_test[4,1:10]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l")
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("bottomright",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```

Por un lado, a partir de 3 genes el F1 score y el accuracy se mantienen bastante constantes. Sin embargo, el porcentaje de acierto a partir de ese valor de genes no llega al 65% y, además, el F1 posteriormente deciende de forma leve. veamos así, la matriz de confusión para el conjunto test y una huella de 3 genes:

```{r, echo=F}
#png('m14.png', width=500, height = 400)
dataPlot(logistic_test_rf$cfMats[[3]]$table, MLLabels, mode = "confusionMatrix")
```

En contraste con el caso anterior, donde la mayor confusión se da entre el glioma mixto y el oligodendroglioma, en este caso, los que más se confunden son el glioma mixto y el astrocitoma. Esto puede ocurrir debido a que ambas clases presentan características similares, lo que dificulta que el modelo las distinga con precisión de nuevo.

### 3.4.3. Selección de variables con FSRankingDA

Se estudia en esta sección la clasificación para el ranking creado con DA.

```{r,  results='hide'}
# Evaluar biomarcadores en TRN. Es multiclase, mejor ver accuracy y F1-Score
logistic_trn_da<- logistic_trn2(MLMatrix, MLLabels, vars_selected = names(FSRankingDA[1:10]))
```

```{r}
logistic_results_da <- rbind(logistic_trn_da$F1Info$meanF1[1:10],logistic_trn_da$accuracyInfo$meanAccuracy)
#dataPlot(svm_results_da, MLLabels, legend = c("F1","Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r, results='hide'}
# Evaluar huella genética en TEST. Es multiclase, mejor ver accuracy y F1-Score
logistic_test_da <- logistic_test_multiclase(MLMatrix, MLLabels, t(XTest), YTest, vars_selected = names(FSRankingDA[1:10]), logistic_trn_da)
logistic_results_da_test <- rbind(logistic_trn_da$F1Info$meanF1[1:10], logistic_test_da$f1Vector, logistic_trn_da$accuracyInfo$meanAccuracy, logistic_test_da$accVector)
```

```{r, echo=F}
#dataPlot(svm_results_da_test, MLLabels, legend = c("Trn F1-score","Test F1-score", "Trn Accuracy","Test Accuracy"), mode = "classResults", xlab="Genes", ylab="Prediction Score")
```

```{r,echo=FALSE}
#png('f15.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- logistic_results_da_test[1,1:10]
Test_F1 <- logistic_results_da_test[2,1:10]
Trn_Acc <- logistic_results_da_test[3,1:10]
Test_Acc <- logistic_results_da_test[4,1:10]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l")
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("bottomright",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```

A partir de 5 genes, parece que las métricas de train y test dejan de tener altibajos. Destaca que estas métricas son más bajas que los resultados obtenidos con los rankings mRMR y RF. Veamos la matriz de confusión para el conjunto test para facilitar la obtención de conclusiones:

```{r, echo=F}
#png('m15.png', width=500, height = 400)
dataPlot(logistic_test_da$cfMats[[5]]$table, MLLabels, mode = "confusionMatrix")
```

La bajada de precisión y de F1 score es debido a la gran confusión del glioma mixto con el oligodendroglioma.

### 3.4.3. Selección de variables con FSRanking_MB

Por último, repitamos el estudio para el ranking de Markov Blanket, entrenando los modelos `logistic_trn_mb` y `logistic_test_mb.` 

```{r, eval=F}
logistic_trn_mb <- logistic_trn2(MLMatrix, MLLabels, vars_selected = FSRanking_MB[1:10])
save(logistic_trn_mb, file='logistic_trn_mb')
```
```{r}
load('logistic_trn_mb')
```

```{r}
logistic_results_mb <- rbind(logistic_trn_mb$F1Info$meanF1[1:10],logistic_trn_mb$accuracyInfo$meanAccuracy)
logistic_test_mb <- logistic_test_multiclase(MLMatrix, MLLabels, t(XTest), YTest, vars_selected = (FSRanking_MB[1:10]), logistic_trn_mb)
logistic_results_mb_test <- rbind(logistic_trn_mb$F1Info$meanF1[1:10], logistic_test_mb$f1Vector, logistic_trn_mb$accuracyInfo$meanAccuracy, logistic_test_mb$accVector)
```

```{r,echo=FALSE}
#png('f16.png',width = 800, height = 600)
num_genes <- 1:10
Trn_F1 <- logistic_results_mb_test[1,1:10]
Test_F1 <- logistic_results_mb_test[2,1:10]
Trn_Acc <- logistic_results_mb_test[3,1:10]
Test_Acc <- logistic_results_mb_test[4,1:10]
plot(num_genes, Trn_F1,"l", col = "green",ylim=c(0,1), ylab='Métricas')
lines(num_genes, Trn_Acc,"l")
lines(num_genes, Test_F1,"l",col = "green",lty = 2)
lines(num_genes, Test_Acc,"l",lty = 2)
legend("topleft",c("Trn F1-score", "Test F1-score", "Trn Accuracy", "Test Accuracy"), col=c("green","green","black","black"),lty=c(1,2,1,2) )
```
De nuevo, parece adecuado escoger una huella de 5 genes ya que seha btenido una gráfica muy silimar a la anterior, pero no igual. Por ello, calculemos la matriz de confusión para el conjunto test y esta huella para visulizar los resultados con más detalle:

```{r, echo=F}
#png('m16.png', width=500, height = 400)
dataPlot(logistic_test_mb$cfMats[[5]]$table, MLLabels, mode = "confusionMatrix")
```

Es cuarioso ya que es una de la mejores clasificaciones de la clase glioma mixto. Sin emebargo, se confunde en bastantes ocasiones el glioma mixto y el astrocitoma con el oligodendroglioma.

### 3.4.5. Conclusiones 

En el caso del clasificador SVM, si seleccionamos características DA o con MB, se tiene un accuracy muy poco superior al 50%. Sin embargo, para el algoritmo de selección mRMR, el accuracy es del 67.3% con muy pocos genes, tres concretamente, y además, este es el porcentaje de acierto el más alto obtenido. También, con el seleccionador Random Forest se obtiene un accuracy para el conjunto test del 63.5%, devolviendo por tanto, una clasificación adecuada pero más pobre que para el mRMR. Por tanto, elegiremos en este caso como mejor seleccionador y huella el mRMR con 3 genes.

# 4.  Resultados bajo el algoritmo de selección y clasificador escogidos en 5CV

En la siguiente sección, se seleccionará la combinación óptima de algoritmo de selección y clasificador, con vista a la sección anterior, y se validará su rendimiento utilizando una validación cruzada de 5 particiones (5CV). Se evaluará el desempeño del modelo en los conjuntos de entrenamiento (Train) y prueba (Test) mediante gráficos que muestran la evolución del número de genes seleccionados y los resultados medios en las cinco particiones. Además, se proporcionarán los cinco rankings de genes más relevantes y se escogerá la huella génica final basada en su consistencia y relevancia.

En primer lugar, el algoritmo de selección de variables elegido es el **mRMR** y el clasificador será **Regresión Logística múltime con penalización**; ya que es con el que se ha obtenido mejores valores de Accuracy, F1, sensibilidad y especificidad. 

```{r, echo=F}
#png('h.png', width = 800, height = 600)
dataPlot(logistic_trn_mrmr, MLLabels, mode='heatmapResults')
```


En segundo lugar, se presenta el siguiente código con el objetivo de mostar resultado, para el modelo de regresión logística con una penalización de $decay = 10^{-4}$ (la objetenida con el modelo `logistic_trn_mrmr` en la sección anterior) y utilizando el seleccionador de características mRMR, en 5CV Trn-Test para todo el dataset:

```{r, results='hide'}
set.seed(19)

nfolds <- 5  # Número de particiones en la validación cruzada
foldIDx <- cvGenStratified(MLLabels, nfolds)  # Particiones estratificadas

nVarsMAX <- 20  # Número máximo de genes a seleccionar, en un ejercicio de clase se aumentó hasta 50

# Matrices para almacenar métricas por partición
ACCTrnRL <- matrix(0, nfolds, nVarsMAX)
ACCTestRL <- matrix(0, nfolds, nVarsMAX)


# Para almacenar los ranking de características de cada partición
rankingSMRMR <- matrix(0, nfolds, nVarsMAX) 

# El Mejor hiperparámetro decay obtenido en la sección enterior
best_decay<-logistic_trn_mrmr$logisticModel$finalModel$decay 
print(best_decay)

# Bucle para 5 particiones
for (particion in seq(1, nfolds)) {
  # Crear particiones de entrenamiento y prueba
  datosParaTRN <- which(foldIDx != particion)  # Índices de entrenamiento
  segmentoTest <- which(foldIDx == particion)  # Índices de prueba
  
  XTrn_P <- as.data.frame( MLMatrix[datosParaTRN, ] ) # Datos de entrenamiento
  XTest_P <- as.data.frame(MLMatrix[segmentoTest, ])  # Datos de prueba
  
  YTrn_P <- as.factor(MLLabels[datosParaTRN])  # Etiquetas de entrenamiento
  YTest_P <- as.factor(MLLabels[segmentoTest])  # Etiquetas de prueba
  
  # Ranking con mRMR
  rankingMRMR <-featureSelection(XTrn_P, YTrn_P, mode = "mrmr", vars_selected = colnames(XTrn_P))
  
  # Guardar POR FILAS el ranking de características para esta partición 
  rankingSMRMR[particion, ] <- rankingMRMR[1:nVarsMAX]

  
  # Evaluación por número de genes seleccionados
  for (numGenes in seq_len(nVarsMAX)) {
    # Seleccionar las mejores variables
    topGenes <- colnames(XTrn_P)[rankingMRMR[1:numGenes]]
    
    # Entrenar modelo Regresión Logística multinomial
    modelo <- multinom(YTrn_P ~ ., data = subset(XTrn_P, select=topGenes), decay = best_decay)
    
    # Predicciones en Train
    predTrain <- predict(modelo, subset(XTest_P, select=topGenes))
    confMatTrain <- confusionMatrix(as.factor(predTrain), as.factor(YTest_P))
    ACCTrnRL[particion, numGenes] <- confMatTrain$overall["Accuracy"]
    
    # Predicciones en Test
    predTest <- predict(modelo, subset(t(XTest), select=topGenes))
    confMatTest <- confusionMatrix(as.factor(predTest), as.factor(YTest)) 
    ACCTestRL[particion, numGenes] <- confMatTest$overall["Accuracy"] # se van añadiendo los valores por filas. Por tanto, para calcular la media de los accuracy para un número determinado de genes que hacerlo por columnas.  #print(confMatTest$overall[1])
    #print(confMatTest$table)
  }
  
  # Graficar los resultados para la partición actual
  num_genes <- 1:nVarsMAX
  Trn_Acc <- ACCTrnRL[particion, 1:nVarsMAX]
  Test_Acc <- ACCTestRL[particion, 1:nVarsMAX]
  
  plot(num_genes, Trn_Acc, type = "l", col = "green", ylim = c(0.5, 1), ylab = "Accuracy",        xlab = "Número de genes seleccionados", main = paste("Partición", particion, "- RL con mRMR"))
  lines(num_genes, Test_Acc, col = "black")
  axis(1, at = 1:20, labels = 1:20)  # Configura los ticks y etiquetas del eje X
  grid()
  legend("topleft", legend = c("Train Accuracy", "Test Accuracy"),col=c("green","black"),lty = c(1, 1))
}

# Medias de Accuracy en las 5 particiones
ACCTrnRL_Mean <- colMeans(ACCTrnRL)
ACCTestRL_Mean <- colMeans(ACCTestRL)

# Resultados promedio
plot(1:nVarsMAX, ACCTrnRL_Mean, type = "l", col = "green", ylim = c(0.5, 1), xlim=c(1,20), xlab = "Número de genes seleccionados", ylab = "Accuracy", main = "Resultados Promedio RL con mRMR")
lines(1:nVarsMAX, ACCTestRL_Mean, col = "black")
axis(1, at = 1:20, labels = 1:20)  # Configura los ticks y etiquetas del eje X
grid()
legend("topleft", legend = c("Train Accuracy", "Test Accuracy"), col = c("green", "black"),
       lty = c(1, 1))

```


```{r}
ACCTrnRL_Mean
```
```{r}
ACCTestRL_Mean
```

```{r}
# Se observan la variable rankingSMRMR
rankingSMRMR[,1:5]
# rankingMRMR de la última iteración pero solo lo utilizamos para saber el nombre de los genes
colnames(MLMatrix)[c(170, 81, 51, 41, 10)]
```


```{r}
# Se observan la variable rankingSMRMR
rankingSMRMR[,1:10]
# rankingMRMR de la última iteración pero solo lo utilizamos para saber el nombre de los genes
colnames(MLMatrix)[c(170, 81, 51, 41, 10)]
```
## 4.1. Resultado de la huella final escogida y clasificador en 5 CV, matriz de confusión final del dataset.

Podemos comenzar esta sección calculando la matriz final del modelo conocida la huella volviendo a probar en 5CV con el número de genes escogidos, es decir, *numGenes <- 5*:

```{r, results='hide'}
set.seed(19)

nfolds <- 5  # Número de particiones en la validación cruzada
foldIDx <- cvGenStratified(LABELS, nfolds)  # Particiones estratificadas

# Vectores para almacenar métricas por partición
ACCTrnRL <- numeric(nfolds)
ACCTestRL <- numeric(nfolds)

# Matriz de confusión acumulada para el test
accTestSum <- matrix(0, nrow = 3, ncol = 3)

# Ranking con mRMR
huella <- c("IGHV3-73", "IGHV6-1", "UBQLN4P1", "PI4K2B", "RAPH1")

# Bucle para 5 particiones
for (particion in seq_len(nfolds)) {
  # Crear particiones de entrenamiento y prueba
  datosParaTRN <- which(foldIDx != particion)  # Índices de entrenamiento
  segmentoTest <- which(foldIDx == particion)  # Índices de prueba
  
  XTrn_P <- as.data.frame(t(MATRIZ[,datosParaTRN])) # Datos de entrenamiento
  XTest_P <- as.data.frame(t(MATRIZ[,segmentoTest]))  # Datos de prueba
  
  YTrn_P <- as.factor(LABELS[datosParaTRN])  # Etiquetas de entrenamiento
  YTest_P <- as.factor(LABELS[segmentoTest])  # Etiquetas de prueba
  
  
  # Entrenar modelo Regresión Logística multinomial
  modelo <- multinom(YTrn_P ~ ., data = subset(XTrn_P, select=huella), decay = best_decay)
  
  # Predicciones en Test
  predTest <- predict(modelo, XTest_P[, huella])
  confMatTest <- confusionMatrix(as.factor(predTest), YTest_P)
  #print(confMatTest$table)
  ACCTestRL[particion] <- confMatTest$overall["Accuracy"]

  
  # Sumar la matriz de confusión al total
  accTestSum <- accTestSum + confMatTest$table
}
```

```{r}
print("Matriz de confusión acumulada en el test:")
accTestSum
```

```{r}
table(LABELS)
```


Finalmente, con estos cinco genes seleccionados, se harán dos particiones sobre MLMatrix y MLLabels, train (80%) y test (20%) con el objetivo de entrenar un modelo regresión logística y buscar los mejores parámetros para este problema con un GridSearch. Para concluir esta sección se predecirán las clases de conjuto test y evaluaremos el desempeño del modelo con una matriz de confusión:

```{r}
# Filtrar los datos para incluir solo los genes seleccionados
X_selected <- as.data.frame( MLMatrix[, c("IGHV3-73", "IGHV6-1", "UBQLN4P1", "PI4K2B", "RAPH1")])# Seleccionar columnas correspondientes
Y <- as.factor(MLLabels)  # Etiquetas de clase

# Crear particiones: 80% Train, 20% Test
set.seed(19)  

trainIndex <- createDataPartition(Y, p = 0.8, list = FALSE)
X_train <- X_selected[trainIndex, ]
Y_train <- Y[trainIndex]
X_test <- X_selected[-trainIndex, ]
Y_test <- Y[-trainIndex]

# GridSearch para Regresión Logística Multinomial: Definir el parámetro decay a probar
grid <- expand.grid(.decay = c(0.0001, 0.01, 0.1, 1))

# Entrenar el modelo con validación cruzada
train_control <- trainControl(method = "cv", number = 5)  # Validación cruzada de 5 pliegues

# Modelo de Regresión Logística Multinomial
logistic_model <- train(x = X_train, y = Y_train, method = "multinom", trControl = train_control, tuneGrid = grid)

# Mejores hiperparámetros encontrados
best_params <- logistic_model$bestTune
best_params

# Entrenar el modelo con el mejor parámetro decay
final_model <- multinom(Y_train ~ ., data = cbind(X_train, Y_train), decay = best_params$decay)

# Predicciones en el conjunto de prueba
pred_test <- predict(final_model, X_test)
conf_matrix <- confusionMatrix(pred_test, Y_test)
conf_matrix
```

En conclusión, el mejor valor de `deacy` es 0.0001, lo que ha permitido obtener una precisión del 65.43% en el conjunto de prueba. Este rendimiento, aunque no es extremadamente alto, aunque refleja un desempeño razonable al clasificar las tres clases. En cuanto a los estadísticos por clase, la sensibilidad es particularmente alta en astrocytoma con un 93.33%, lo que indica que el modelo es eficaz para identificar correctamente los positivos en esta clase, al igual que para la clase oligodendroglioma con un 80% de acierto. Por ello, el Balanced Accuracy, que considera tanto la sensibilidad como la especificidad, muestra buenos valores, especialmente en astrocytoma (83.92%) y oligodendroglioma (77.25%). Sin embargo, el valor predictivo positivo es algo bajo en mixed_glioma (33.33%), pero aún se mantiene a un buen nivel en astrocytoma (68.29%) y oligodendroglioma (64.86%). Así, es importante destacar que mixed_glioma presenta un desafío, con una sensibilidad baja (4.76%) y un rendimiento general más débil, lo que se refleja en los errores de clasificación en la matriz de confusión.


# 5. Enriquecimiento de los genes de la huella escogida

Por último, en esta sección, se realizará un análisis de enriquecimiento funcional de los tres genes seleccionados en la huella final (**IGHV3-73**, **IGHV6-1**, **UBQLN4P1**, **PI4K2B** y **RAPH1**), identificando su participación en procesos biológicos (Gene Ontology - GO), rutas metabólicas y celulares (Pathways) y su asociación con enfermedades (Disease Association). Los resultados obtenidos permitirán no solo diferenciar con mayor precisión las muestras de LUAD, LUSC y tejido sano, sino también identificar potenciales biomarcadores que puedan contribuir a futuros estudios sobre el diagnóstico y tratamiento del cáncer de pulmón.

Primero, se utiliza la función "*getGenesAnnotationpara*" mapear los nombres de los genes (**IGHV3-73**, **IGHV6-1**, **UBQLN4P1**, **PI4K2B** y **RAPH1**) a identificadores Entrez Gene. Estos identificadores son necesarios para muchos análisis funcionales, ya que son un estándar en bases de datos biológicos como GO, pathways y diseases que se verán a continuación.

```{r, results='hide'}
#ENRIQUECIMIENTO FUNCIONAL:
entrezAnnotation <- getGenesAnnotation(c("IGHV3-73", "IGHV6-1", "UBQLN4P1", "PI4K2B", "RAPH1"), attributes = c("external_gene_name","entrezgene_id"), filter = "external_gene_name")
entrezGeneIds<- entrezAnnotation$entrezgene_id[!is.na(entrezAnnotation$entrezgene_id)]
```

```{r}
entrezAnnotation
```

Así, el gen **PI4K2B** y el **RAPH1** serán los únicos que no se ignore por tener identificador Entrez y ser los únicos que se mapean. Con estos genes pasemos al análisis de enriquecimiento funcional utilizando Gene Ontology:

```{r, eval=F}
# Se descarga informacion sobre los Gene Ontology
GOs <- geneOntologyEnrichment_updated(as.character(entrezGeneIds), geneType = "ENTREZ_GENE_ID")
save(GOs, file='GOs')
```

```{r}
load('GOs')
GOs
```

En la tabla anterior se han mostrado los términos GO asosiados al gen **PI4K2B** y al gen **RAPH1**, los cuales están asociado principalmente con procesos biológico (BP):

- Asociados al **PI4K2B**: el proceso biosintético del fosfatidilinositol y del fosfatidilinositol fosfato, la organización de vesículas y la organización del Golgi.
- Asociados al **RAPH1**: axogénesis (el proceso mediante el cual las neuronas se desarrollan y extienden sus axones ), crecimiento del desarrollo involucrado en la morfogénesis y extensión de las proyecciones neuronales.

El gen gen **PI4K2B** también se asocia con funciones moleculares (MF), como por ejemplo:

- La actividad de la quinasa de fosfatidilinositol.
- La actividad de la quinasa lipídica.

Y, tanto **PI4K2B** como **RAPH1**, se asocian con componentes celulares (CC):

- Asociados con **PI4K2B**: Red del Golgi-trans: la red de vesículas que clasifica y envía proteínas y lípidos a sus destinos, subcompartimento del aparato de Golgi. endosoma temprano, actividad de quinasa de fosfatidilinositol: actividad enzimática responsable de la fosforilación del fosfatidilinositol, un lípido involucrado en la transducción de señales.
- Asociados con **RAPH1**: borde principal celular, lamelipodio y filopodio.


Por otro lado, veamos los genes más enriquecidos observando la variable de GOs: **GeneRatio**. Sin embargo, esta variable vale en todos los casos 1/2 luego no podemos llegar a ninguna conclusión, a priori.

Otra posibilidad es crear un vector con los p-values ajustados ordenados de menor a mayor. Cuanto menor sea el **p.ajust**, más significativo será el término GO. Se muestran, entonces, los cinco términos más enriquecidos:

```{r}
sort(GOs$p.adjust, decreasing = F)[1:5]
posiciones<-order(GOs$p.adjust, decreasing = F)[1:5]
posiciones
rownames(GOs)[posiciones][1:5]
GOs$Description[posiciones]
GOs$geneID[posiciones]
```
La mayoría de los genes enriquecidos están asocidos al **PI4K2B**.

En segundo lugar, veamos la función de enriquecimiento funcional: `DEGsToPathways`, la cual descarga información sobre los Pathways, es decir, rutas metabólicas y celulares:

```{r, results='hide'}
pathways <- DEGsToPathways(entrezAnnotation$external_gene_name)
pathways_df <- data.frame(
  Kegg_path = unlist(pathways$KEGG_Path),
  Name = unlist(pathways$Name),
  Description = unlist(pathways$Description),
  Class = unlist(pathways$Class),
  Genes = unlist(pathways$Genes)
)
```
```{r}
pathways_df
```

En este caso, el gen **PI4K2B** está presente en las tres rutas metabólicas, es decir, en los tres pathways. Veamos a que clase pertece cada ruta metabólica:

- map00562 pertenece al metabolismo de los carbohidrados.
- map01100 está listado, pero no tiene una descripción específica asociada, por lo que no podemos determinar su categoría.
- map04070 pertenece a la categoría de Procesamiento de Información Ambiental; Transducción de Señales, que abarca cómo las células perciben y responden a señales provenientes del entorno, como estímulos químicos o físicos. 


La tercera y última forma de enriquecimiento funcional que se tarta en este proyecto, viene dada por la función `DEGsToDiseases`. Con ella se descarga información sobre las enfermedades relacionadas y busca las evidencias de que esos genes esten asociados a esas enfermedades.

```{r, results='hide'}
diseases <- DEGsToDiseases(entrezAnnotation$external_gene_name, getEvidences = TRUE)
```
- *entrezAnnotation$external_gene_name*: se pasan los nombres de los genes de interés, en nuestro caso la huella escogida.
- *getEvidences = TRUE*: al activar este parámetro, la función recupera las enfermedades asociadas con esos genes y obtiene las evidencias científicas que respaldan dichas asociaciones, como estudios previos, artículos de investigación y bases de datos.

```{r}
diseases
```

La información proporcionada se refiere a nuestros genes con identificadores Entrez: **PI4K2B** y **RAPH1**, junto con las **enfermedades** asociadas a ellos y los respectivos **puntajes de asociación**. Aunque en el segundo caso aparezca NA, tras varias comprobaciones he descubierto que se refiere al gen **RAPH1**.

En primer lugar, el gen **PI4K2B** está asociado con diversas condiciones, aunque los puntajes de asociación son relativamente bajos. Las enfermedades con mayores *Overall Score*, es decir, más relacionadas con el gen, son: **adenocarcinoma de mama**, **medición de proteínas** y **carcinoma escamoso de cabeza y cuello**. En cuanto a la **medición de proteínas**, la asociación genética muestra un puntaje de 0.391, lo que indica cierta relación genética entre **PI4K2B** y esta condición. Sin embargo, para muchas otras enfermedades, no se observan asociaciones significativas, ya que los puntajes de Genetic Assoc. son todos "0". Destaca también, el caso del **autismo**, que presenta un puntaje de 0.1945 en asociación genética, lo que sugiere una relación con el gen **PI4K2B**, aunque es débil. En relación con la evidencia en literatura, el único valor relevante se encuentra en el **carcinoma pulmonar de células pequeñas**, con un puntaje de 0.468 y el **adenocarcinoma de pulmón** con un puntuaje de 0.012. Esto indica que **PI4K2B** tiene una expresión moderada en este tipo de cáncer y evidencias disponibles en la literatura.

Por otro lado, en la mayoría de las enfermedades y condiciones mencionadas (como **autismo**, **medición de proteínas sanguíneas**, o **microbioma intestinal**), tanto la expresión de ARN como las mutaciones somáticas, los fármacos conocidos y los modelos animales no muestran evidencia fuerte, ya que todos los valores están en "0".


En segundo lugar, el gen **RAPH1** parece que tiene más asociación con las enfermedades neurodegenerativas (*Ovarall Score* = 0.53), así como con la **medición de la microestructura de la sustancia blanca**, es decir, con el análisis detallado de las fibras nerviosas; y la **medición de la apolipoproteína B** lo que implica evaluar los niveles de una proteína vinculada al transporte de lípidos, cuya alteración puede estar asociada con enfermedades cardiovasculares y neurodegenerativas. Además, estas dos últimas enfermedades son las que presentan valores más altos en *asociación genética*. Sin embargo, en relación con la literatura, expresión de ARN, fármacos conocidos o modelos animales no se proporciona ninguna información.

En cuanto a mutaciones somáticas para el gen **RAPH1**, se observa que la mayoría de las enfermedades listadas no tienen mutaciones somáticas registradas, ya que los valores en esta columna son "0" para muchas de ellas. Sin embargo, hay dos excepciones: el **carcinoma de próstata** y el **cáncer de próstata familiar**, que tienen un valor de 0.1824, indicando una presencia mínima de mutaciones somáticas asociadas con este gen. Esto sugiere que, aunque la mutación somática no es un factor dominante en la mayoría de los casos, podría tener alguna relevancia en ciertos tipos de cáncer, como los relacionados con la próstata.

Finalmente, los valores de *Affected Pathways* son más altos en ciertas condiciones, como en el **adenocarcinoma de mama**, en el caso del **PI4K2B**, donde la vía afectada muestra un valor de 0.8086, indicando este gen podría estar involucrado en la regulación de ciertas vías metabólicas o celulares relevantes para este tipo de cáncer. Además, para el **RAPH1** solo hay un valor para el *Affected Pathways* y es de 0.862 lo que indica que este gen podría estar involucrado en la regulación de vías metabólicas o celulares específicas que desempeñan un papel importante en los procesos asociados a las **enfermedades neurodegenerativas**.

